---
title: "Impact de l'information (Q1 avant vs Q2 après)"
format:
  html:
    toc: true
    toc-title: "Table des matières"
    toc-depth: 3
    number-sections: true
    toc-location: left
    df-print: paged
  pdf:
    toc: true
    toc-title: "Table des matières"
    toc-depth: 3
    number-sections: true
execute:
  echo: false
  warning: false
  message: false
---

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

# Utile en environnement "sandbox" : forcer les caches R dans le projet
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
cache_dir <- file.path(getwd(), ".r_cache")
dir.create(cache_dir, showWarnings = FALSE, recursive = TRUE)
Sys.setenv(R_USER_CACHE_DIR = cache_dir)
Sys.setenv(XDG_CACHE_HOME = cache_dir)

library(dplyr)
library(tidyr)
library(readr)
library(tibble)
library(ggplot2)
library(gtsummary)
library(rstatix)
library(leaflet)
```

```{r}
#| label: functions
#| echo: false
#| message: false
#| warning: false
col_pre <- "#4C78A8"  # Avant (Q1) - bleu
col_post <- "#54A24B" # Après (Q2) - vert
col_neg <- "#E45756"  # Diminution / négatif - rouge
col_neutral <- "grey70" # Stable / neutre
col_lang_fr <- "#1B9E77" # Langue - Français (vert)
col_lang_cr <- "#D95F02" # Langue - Créole (orange)
alpha <- 0.05

theme_article <- function(base_size = 12) {
  theme_minimal(base_size = base_size) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = "top"
    )
}

fmt_p <- function(p) {
  vapply(p, function(pi) {
    if (is.na(pi)) return("NA")
    if (pi < 1e-4) return("< 1e-4")
    formatC(pi, format = "f", digits = 4)
  }, character(1))
}

fmt_num <- function(x, digits = 2) {
  if (is.na(x)) return("NA")
  scales::number(x, accuracy = 10^-digits, decimal.mark = ",")
}

sig_txt <- function(p, alpha = 0.05) {
  if (is.na(p)) return("non interprétable")
  if (p < alpha) "statistiquement significatif" else "non statistiquement significatif"
}

stars_from_p <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.001) return("***")
  if (p < 0.01) return("**")
  if (p < 0.05) return("*")
  ""
}

wilson_ci <- function(x, n, conf.level = 0.95) {
  if (n <= 0) return(c(NA_real_, NA_real_))
  z <- qnorm(1 - (1 - conf.level) / 2)
  phat <- x / n
  denom <- 1 + (z^2) / n
  center <- (phat + (z^2) / (2 * n)) / denom
  half <- (z * sqrt((phat * (1 - phat) + (z^2) / (4 * n)) / n)) / denom
  c(max(0, center - half), min(1, center + half))
}
```

```{r}
#| label: scoring_key
#| echo: false
#| message: false
#| warning: false
# --- Clé de correction (Questionnaire_Version_corrigee.pdf) ---
norm_txt <- function(x) {
  x <- ifelse(is.na(x), "", x)
  x <- tolower(trimws(x))
  x <- gsub("[\u2018\u2019\u201B\u2032]", "'", x) # apostrophes
  x <- gsub("[\u201C\u201D\u2033]", "\"", x)      # guillemets
  x <- iconv(x, from = "", to = "ASCII//TRANSLIT", sub = "")
  x <- gsub("[[:space:]]+", " ", x)
  trimws(x)
}

split_choices <- function(x) {
  if (is.na(x) || x == "") return(character(0))
  parts <- unlist(strsplit(x, "\r?\n"))
  parts <- trimws(parts)
  parts <- parts[parts != ""]
  parts
}

score_response <- function(response, correct_options, points) {
  if (is.na(response) || response == "") return(0)
  selected <- norm_txt(split_choices(response))
  correct_n <- norm_txt(correct_options)
  pts <- as.numeric(points)
  names(pts) <- correct_n
  sum(pts[intersect(selected, correct_n)], na.rm = TRUE)
}

key <- tibble(
  id = c(
    "Q1_nuit",
    "Q2_transfert",
    "Q3_consequences",
    "Q4_SAF",
    "Q5_detection",
    "Q6_quantite",
    "Q7_verres",
    "Q8_place_homme"
  ),
  label = c(
    "Boire de l’alcool pendant la grossesse nuit au bébé ?",
    "L’alcool bu par la mère arrive jusqu’au bébé ?",
    "Conséquences possibles sur le bébé à naître",
    "Conséquences du SAF",
    "Âges possibles de détection des troubles",
    "Quantité d’alcool risquée pendant la grossesse",
    "Verre contenant le plus d’alcool",
    "Place de l’homme dans la prévention"
  ),
  q1_col = c(
    "Q1__Pensez-vous que boire de l’alcool pendant la grossesse peut nuire au bébé ?",
    "Q1__Est-ce que l’alcool bu par la mère arrive jusqu’au bébé ?",
    "Q1__Quelles peuvent être les conséquences de l’alcool sur le bébé à naître ?",
    "Q1__Le syndrome d’alcoolisation fœtale (SAF) est la conséquence la plus grave de l’alcool pendant la grossesse. Que provoque-t-il ?",
    "Q1__À quel âge peut-on détecter les troubles liés à l’alcool pendant la grossesse ?",
    "Q1__Quelle quantité d’alcool est risquée pendant la grossesse ?",
    "Q1__Lequel de ces verres contient le plus d’alcool ?",
    "Q1__Quelle peut être la place de l’homme dans la prévention des risques liés à l’alcool pendant la grossesse ?"
  ),
  q2_col = c(
    "Q2__Pensez-vous que boire de l’alcool pendant la grossesse peut nuire au bébé ?",
    "Q2__Est-ce que l’alcool bu par la mère arrive jusqu’au bébé ?",
    "Q2__Quelles peuvent être les conséquences de l’alcool sur le bébé à naître ?",
    "Q2__Le syndrome d’alcoolisation fœtale (SAF) est la conséquence la plus grave de l’alcool pendant la grossesse. Que provoque-t-il ?",
    "Q2__À quel âge peut-on détecter les troubles liés à l’alcool pendant la grossesse ?",
    "Q2__Quelle quantité d’alcool est risquée pendant la grossesse ?",
    "Q2__Lequel de ces verres contient le plus d’alcool ?",
    "Q2__Quelle peut être la place de l’homme dans la prévention des risques liés à l’alcool pendant la grossesse ?"
  ),
  max_points = c(5, 5, 6, 5, 5, 5, 5, 4),
  correct_options = list(
    c("OUI"),
    c("OUI"),
    c(
      "Un arrêt précoce de grossesse",
      "Une malformation du cœur",
      "Des troubles psychiatriques",
      "Une mort subite du nourrisson",
      "De l’épilepsie",
      "Des retards de développement neurologique"
    ),
    c(
      "Un retard mental",
      "Un retard de croissance (petit poids et petite taille)",
      "Une déficience visuelle",
      "Des troubles du comportement",
      "Des malformations du visage"
    ),
    c(
      "Dans le ventre de la mère",
      "Dès 6 ans",
      "À l'adolescence",
      "À l’âge adulte",
      "Tout au long de la vie"
    ),
    c("Dès le premier verre"),
    c("Tous contiennent la même quantité d’alcool"),
    c(
      "Lui aussi pourrait causer des troubles à l’enfant s’il consomme de l’alcool",
      "Il devrait arrêter l’alcool",
      "Il devrait être plus présent pour sa femme"
    )
  ),
  points = list(
    c(5),
    c(5),
    rep(1, 6),
    rep(1, 5),
    rep(1, 5),
    c(5),
    c(5),
    c(2, 1, 1)
  )
)

stopifnot(sum(key$max_points) == 40)

compute_total_score20 <- function(data) {
  pre_total40 <- numeric(nrow(data))
  post_total40 <- numeric(nrow(data))
  for (i in seq_len(nrow(key))) {
    q <- key[i, ]
    pre_total40 <- pre_total40 + vapply(
      data[[q$q1_col]],
      score_response,
      numeric(1),
      q$correct_options[[1]],
      q$points[[1]]
    )
    post_total40 <- post_total40 + vapply(
      data[[q$q2_col]],
      score_response,
      numeric(1),
      q$correct_options[[1]],
      q$points[[1]]
    )
  }
  tibble(score_pre_calc = pre_total40 / 2, score_post_calc = post_total40 / 2)
}
```

## Introduction

### Objectif

Objectif principal : évaluer l'impact d'une information sur les connaissances des risques de l'alcool pendant la grossesse, en comparant le **score global** avant (Q1) et après (Q2) information, chez les mêmes participantes.

Objectifs secondaires : décrire (i) la proportion de participantes ayant un gain >= 3 points, (ii) l'évolution individuelle (spaghetti), (iii) les évolutions **par question**, et (iv) l'hétérogénéité des scores/gains selon l'âge (exploratoire).

### Méthodes

::: {.callout-note title="Approche méthodologique en résumé"}
Il s’agit d’une étude **avant–après** visant à mesurer l'évolution des connaissances des participantes suite à une intervention d'information. La même population a répondu à un questionnaire avant (Q1) puis après (Q2).

L'analyse repose sur la comparaison des scores Q1 et Q2 **chez des patientes appairées**, ce qui est la méthode la plus fiable pour mesurer un changement.

En l'absence de critère d'indentification unique, l'appariement a été réalisé via des identifiants partiels (âge et commune de résidence), puis validé manuellement. Seules les paires complètes (Q1 et Q2) ont été retenues pour l'analyse principale.

-   **Tests statistiques :** On utilise le **test t apparié** pour vérifier que l'amélioration n'est pas due au hasard. *Une méthode de bootstrap permet de réaliser un test t sans présupposer de normalité des données.*
-   **Quantification de l'effet :** On calcule le **gain moyen** et son **intervalle de confiance à 95%** pour connaître la taille de l'amélioration et sa plage de valeurs plausibles. Le **bootstrap** valide ces résultats sans présupposer de la normalité des données.
-   **Pertinence et effet plafond :** On analyse la proportion de participantes avec un **gain >= 3 points** et on utilise une **régression logistique** pour comprendre comment la probabilité d'un "gros gain" diminue quand le score de départ est déjà élevé.
-   **Analyses exploratoires :** On regarde ensuite les différences par **âge** et par **question** pour affiner la compréhension.
:::

Il s’agit d’une étude avant–après à données appariées évaluant l’impact d’une information sur les connaissances des participantes sur les risques de l'alcool pendant la grossesse, mesurées par deux passations d’un questionnaire (Q1 avant, Q2 après). 

L'appariement des patientes a été réalisé via des identifiants partiels (âge et commune de résidence), puis validé manuellement. Seules les paires complètes ont été retenues pour l’analyse principale. Le critère de jugement principal est le score global, recalculé à partir des réponses à l’aide d’une clé de correction et d’un barème prédéfinis : les points des 8 questions sont sommés (total /40), puis divisés par 2 pour obtenir une note sur 20. Pour les questions à réponses multiples, un point est attribué à chaque proposition correcte selon le barème ; aucune pénalité n’est appliquée en cas de réponses supplémentaires non attendues. Les scores par question (en points, de 0 au maximum de la question) et le gain individuel (Q2 − Q1) ont également été calculés ; pour comparer des questions de barèmes différents, les gains ont aussi été exprimés en pourcentage du barème.

Les variables quantitatives sont décrites par moyenne ± écart-type (et médiane [IQR] lorsque pertinent) et les variables qualitatives par effectif et pourcentage. L’effet global de l’intervention sur le score global a été évalué en comparant Q1 et Q2 au sein des mêmes participantes, à l’aide d’un test t apparié (Student), dans le sens “après > avant”, en appliquant une procédure de *bootstrap* (1000 réplications) pour s'affranchir de l’hypothèse de normalité des données. La pertinence clinique a été décrite en (i) comparant le gain moyen au seuil de 3 points et (ii) calculant la proportion de participantes atteignant un gain >= 3 points (avec intervalle de confiance binomial). Un test de signe (binomial) a également été utilisé pour comparer la fréquence des améliorations (gain > 0) à celle des diminutions (gain < 0), en ignorant les égalités. Enfin, une analyse exploratoire a estimé la probabilité d’un gain >= 3 points en fonction du score initial, de l’âge (approché en années) et de la langue du questionnaire (français vs créole), via une régression logistique multivariable.

Des analyses exploratoires ont étudié l’hétérogénéité des scores initiaux et des gains selon la tranche d’âge (tests de Kruskal–Wallis et modèle linéaire ajusté sur le score initial). Enfin, des analyses par question ont comparé les scores avant/après (tests appariés) et décrit les distributions de scores en points (proportions avec intervalles de confiance de Wilson), avec des tests de McNemar par niveau de score (p < 0,05). Ces analyses “par question” sont présentées à titre exploratoire, sans correction de multiplicité. Toutes les analyses ont été conduites sous R 4.5.2, avec un seuil de significativité de 5% (alpha = 0,05) et des intervalles de confiance à 95%.

## Données et préparation

### Données

Ce rapport utilise le fichier apparié `Q1_Q2_apparie.csv` (1 ligne = 1 participante du Q1, appariée à une ligne du Q2 quand possible).


```{r}
data_raw <- readr::read_delim(
  "Q1_Q2_apparie.csv",
  delim = ";",
  locale = locale(encoding = "UTF-8"),
  show_col_types = FALSE,
  trim_ws = TRUE
)

q2_raw <- readr::read_delim(
  "Q2_v2_merged.csv",
  delim = ";",
  locale = locale(encoding = "UTF-8"),
  col_types = cols(.default = col_character()),
  show_col_types = FALSE,
  trim_ws = TRUE
)

q2_scores <- q2_raw %>%
  transmute(
    score_q2_total_reported = readr::parse_number(
      `Bravo ! Vous avez obtenu la note de :`,
      locale = locale(decimal_mark = ",")
    )
  ) %>%
  filter(!is.na(score_q2_total_reported))

data <- data_raw %>%
  mutate(
    has_match = !is.na(Q2_row) & Q2_row != "",
    langue_q1 = dplyr::case_when(
      tolower(Q1__Langue) %in% c("français", "francais") ~ "Français",
      tolower(Q1__Langue) %in% c("créole", "creole") ~ "Créole",
      TRUE ~ "Inconnu"
    ),
    langue_q2 = dplyr::case_when(
      tolower(Q2__Langue) %in% c("français", "francais") ~ "Français",
      tolower(Q2__Langue) %in% c("créole", "creole") ~ "Créole",
      TRUE ~ "Inconnu"
    ),
    age_group = dplyr::case_when(
      age_key == "moins de 18 ans" ~ "Moins de 18 ans",
      age_key == "entre 18 et 24 ans" ~ "Entre 18 et 24 ans",
      age_key == "entre 25 et 29 ans" ~ "Entre 25 et 29 ans",
      age_key == "entre 30 et 34 ans" ~ "Entre 30 et 34 ans",
      age_key == "entre 35 et 39 ans" ~ "Entre 35 et 39 ans",
      age_key == "entre 40 et 44 ans" ~ "Entre 40 et 44 ans",
      age_key == "entre 45 et 49 ans" ~ "Entre 45 et 49 ans",
      age_key == "50 ans et plus" ~ "50 ans et plus",
      TRUE ~ "Inconnu"
    ),
    age_years = dplyr::case_when(
      age_key == "moins de 18 ans" ~ 17,
      age_key == "entre 18 et 24 ans" ~ 21,
      age_key == "entre 25 et 29 ans" ~ 27,
      age_key == "entre 30 et 34 ans" ~ 32,
      age_key == "entre 35 et 39 ans" ~ 37,
      age_key == "entre 40 et 44 ans" ~ 42,
      age_key == "entre 45 et 49 ans" ~ 47,
      age_key == "50 ans et plus" ~ 52,
      TRUE ~ NA_real_
    ),
    age_group = factor(
      age_group,
      levels = c(
        "Moins de 18 ans",
        "Entre 18 et 24 ans",
        "Entre 25 et 29 ans",
        "Entre 30 et 34 ans",
        "Entre 35 et 39 ans",
        "Entre 40 et 44 ans",
        "Entre 45 et 49 ans",
        "50 ans et plus",
        "Inconnu"
      )
    ),
    langue_q1 = factor(langue_q1, levels = c("Français", "Créole", "Inconnu")),
    langue_q2 = factor(langue_q2, levels = c("Français", "Créole", "Inconnu"))
  )

scores_all <- compute_total_score20(data)
data <- bind_cols(data, scores_all)

data_matched <- data %>% filter(has_match)

n_q1 <- nrow(data)
n_q2_total <- nrow(q2_scores)
n_q2_matched <- nrow(data_matched)
```

### Préparation des scores

```{r}
#| output: false
data_matched <- data_matched %>%
  mutate(
    score_pre_reported = as.numeric(Q1_score_utilisee),
    score_post_reported = as.numeric(Q2_score_utilisee)
  ) %>%
  filter(!is.na(score_pre_reported), !is.na(score_post_reported))

data_matched <- data_matched %>%
  mutate(
    score_pre = score_pre_calc,
    score_post = score_post_calc,
    score_diff = score_post - score_pre,
    diff_pre_vs_reported = score_pre_calc - score_pre_reported,
    diff_post_vs_reported = score_post_calc - score_post_reported
  )

data_matched %>%
  summarise(
    n = n(),
    mismatch_pre = sum(abs(diff_pre_vs_reported) > 1e-6),
    mismatch_post = sum(abs(diff_post_vs_reported) > 1e-6),
    max_abs_pre = max(abs(diff_pre_vs_reported)),
    max_abs_post = max(abs(diff_post_vs_reported))
  )

summary(data_matched$score_pre)
summary(data_matched$score_post)
summary(data_matched$score_diff)
```

```{r}
#| output: false
# Affiche les éventuelles discordances (score reporté vs score recalculé)
data_matched %>%
  filter(abs(diff_pre_vs_reported) > 1e-6 | abs(diff_post_vs_reported) > 1e-6) %>%
  select(Q1_row, score_pre_reported, score_pre_calc, diff_pre_vs_reported, score_post_reported, score_post_calc, diff_post_vs_reported) %>%
  arrange(desc(abs(diff_pre_vs_reported))) %>%
  head(10)
```

```{r}
# Variables résumées pour le "langage simple"
delta_clin <- 3
gain_mean_simple <- mean(data_matched$score_diff, na.rm = TRUE)
baseline_mean_simple <- mean(data_matched$score_pre, na.rm = TRUE)
prop_ge_3_simple <- mean(data_matched$score_diff >= delta_clin, na.rm = TRUE)

tt_simple <- t.test(data_matched$score_post, data_matched$score_pre, paired = TRUE, alternative = "greater")
tt_ci_simple <- t.test(data_matched$score_post, data_matched$score_pre, paired = TRUE, alternative = "two.sided")

kw_age_simple <- kruskal.test(
  score_diff ~ age_group,
  data = data_matched %>% filter(age_group != "Inconnu")
)
```

## Description



Pour visualiser la portée de l'étude, la carte suivante montre la répartition des participantes sur l'île de La Réunion. Chaque commune est représentée par un marqueur, dont la couleur et la taille reflètent le nombre de répondantes.

```{r}
#| label: map_reunion
#| fig-width: 8
#| fig-height: 7
#| message: false
#| warning: false
#| echo: false

# NOTE (important) : le rendu Quarto peut s'exécuter sans accès réseau. La carte Leaflet est bien générée
# dans le HTML, mais le fond de carte (tuiles) se charge au moment de l'ouverture du HTML dans le navigateur.

normalize_city_name <- function(name) {
  name %>%
    tolower() %>%
    iconv(to = "ASCII//TRANSLIT") %>%
    stringr::str_squish() %>%
    stringr::str_replace_all(c("st\\b" = "saint", "ste\\b" = "sainte")) %>%
    stringr::str_replace_all("[^a-z0-9 ]+", " ") %>%
    stringr::str_squish()
}

recode_to_commune <- function(city_norm) {
  dplyr::case_when(
    is.na(city_norm) ~ NA_character_,
    stringr::str_detect(city_norm, "\\bsaint denis\\b|\\bla montagne\\b|\\bsainte clotilde\\b") ~ "Saint-Denis",
    stringr::str_detect(city_norm, "\\bsainte marie\\b") ~ "Sainte-Marie",
    stringr::str_detect(city_norm, "\\bsainte suzanne\\b") ~ "Sainte-Suzanne",
    stringr::str_detect(city_norm, "\\bsaint andre\\b") ~ "Saint-André",
    stringr::str_detect(city_norm, "\\bbras panon\\b") ~ "Bras-Panon",
    stringr::str_detect(city_norm, "\\bsaint benoit\\b") ~ "Saint-Benoît",
    stringr::str_detect(city_norm, "plaine des palmistes") ~ "La Plaine-des-Palmistes",
    stringr::str_detect(city_norm, "\\bsalazie\\b|\\bhell bourg\\b") ~ "Salazie",
    stringr::str_detect(city_norm, "\\bsainte rose\\b") ~ "Sainte-Rose",
    stringr::str_detect(city_norm, "\\bsaint philippe\\b") ~ "Saint-Philippe",
    stringr::str_detect(city_norm, "\\bsaint joseph\\b") ~ "Saint-Joseph",
    stringr::str_detect(city_norm, "petite ile") ~ "Petite-Île",
    stringr::str_detect(city_norm, "\\bsaint pierre\\b|\\bbois d olives\\b|\\bligne paradis\\b") ~ "Saint-Pierre",
    stringr::str_detect(city_norm, "\\ble tampon\\b|\\btampon\\b") ~ "Le Tampon",
    stringr::str_detect(city_norm, "entre deux") ~ "Entre-Deux",
    stringr::str_detect(city_norm, "\\bcilaos\\b") ~ "Cilaos",
    stringr::str_detect(city_norm, "\\bsaint louis\\b|\\bla riviere\\b") ~ "Saint-Louis",
    stringr::str_detect(city_norm, "etang sale") ~ "L'Étang-Salé",
    stringr::str_detect(city_norm, "\\bles avirons\\b|\\bavirons\\b") ~ "Les Avirons",
    stringr::str_detect(city_norm, "\\bsaint leu\\b|\\bpiton saint leu\\b") ~ "Saint-Leu",
    stringr::str_detect(city_norm, "trois bassins") ~ "Les Trois-Bassins",
    stringr::str_detect(city_norm, "\\bsaint paul\\b|\\bsaint gilles\\b|\\bla saline\\b|\\bsaline les bains\\b|\\bboucan canot\\b") ~ "Saint-Paul",
    stringr::str_detect(city_norm, "\\ble port\\b") ~ "Le Port",
    stringr::str_detect(city_norm, "\\bla possession\\b") ~ "La Possession",
    TRUE ~ NA_character_
  )
}

# Coordonnées (centroïdes approximatifs) des 24 communes de La Réunion
commune_coords <- tibble::tribble(
  ~commune, ~lat, ~lon,
  "Les Avirons", -21.2419, 55.3333,
  "Bras-Panon", -20.9953, 55.6761,
  "Entre-Deux", -21.2486, 55.4703,
  "L'Étang-Salé", -21.2661, 55.3669,
  "Petite-Île", -21.3400, 55.5700,
  "La Plaine-des-Palmistes", -21.1350, 55.6256,
  "Le Port", -20.9394, 55.2872,
  "La Possession", -20.9264, 55.3358,
  "Saint-André", -20.9606, 55.6506,
  "Saint-Benoît", -21.0339, 55.7128,
  "Saint-Denis", -20.8789, 55.4481,
  "Saint-Joseph", -21.3786, 55.6192,
  "Saint-Leu", -21.1664, 55.2869,
  "Saint-Louis", -21.2867, 55.4092,
  "Saint-Paul", -21.0097, 55.2697,
  "Saint-Pierre", -21.3419, 55.4778,
  "Saint-Philippe", -21.3594, 55.7678,
  "Sainte-Marie", -20.8969, 55.5492,
  "Sainte-Rose", -21.1272, 55.7922,
  "Sainte-Suzanne", -20.9056, 55.6072,
  "Salazie", -21.0278, 55.5392,
  "Le Tampon", -21.2781, 55.5153,
  "Les Trois-Bassins", -21.1058, 55.2950,
  "Cilaos", -21.1353, 55.4711
)

city_counts <- data %>%
  mutate(city_norm = normalize_city_name(`Q1__Dans quelle ville habitez-vous ?`)) %>%
  mutate(commune = recode_to_commune(city_norm)) %>%
  filter(!is.na(commune)) %>%
  count(commune, name = "n_participants")

map_data <- commune_coords %>%
  left_join(city_counts, by = "commune") %>%
  mutate(n_participants = tidyr::replace_na(n_participants, 0L)) %>%
  filter(n_participants > 0)

pal <- leaflet::colorNumeric(
  # Palette plus contrastée (type "plasma") pour mieux ressortir sur un fond de carte gris.
  palette = c(
    "#0d0887", "#46039f", "#7201a8", "#9c179e", "#bd3786",
    "#d8576b", "#ed7953", "#fb9f3a", "#fdca26", "#f0f921"
  ),
  domain = map_data$n_participants
)

m <- leaflet::leaflet(map_data) %>%
  leaflet::addProviderTiles(leaflet::providers$CartoDB.Positron) %>%
  leaflet::setView(lng = 55.52, lat = -21.12, zoom = 10) %>%
  leaflet::addCircleMarkers(
    lng = ~lon,
    lat = ~lat,
    radius = ~pmax(4, sqrt(n_participants) * 4),
    color = "#111111",
    weight = 2,
    fillColor = ~pal(n_participants),
    fillOpacity = 0.9,
    label = ~paste0(commune, " : ", n_participants),
    popup = ~paste0("<b>", commune, "</b><br/>n = ", n_participants)
  ) %>%
  leaflet::addLegend(
    position = "bottomright",
    pal = pal,
    values = ~n_participants,
    title = "Effectif (Q1)",
    opacity = 0.9
  )

if (knitr::is_html_output()) {
  m
} else {
  # Version PDF : Leaflet n'est pas interactif.
  # Option A (si dispo) : capture d'écran de la carte Leaflet via webshot2.
  # Option B : tableau récapitulatif.
  if (requireNamespace("webshot2", quietly = TRUE) &&
      requireNamespace("chromote", quietly = TRUE) &&
      requireNamespace("htmlwidgets", quietly = TRUE)) {
    out_dir <- "analyse_intervention_files"
    dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)
    tmp_html <- file.path(out_dir, "map_reunion_leaflet.html")
    tmp_png <- file.path(out_dir, "map_reunion_leaflet.png")
    htmlwidgets::saveWidget(m, tmp_html, selfcontained = TRUE)
    webshot2::webshot(tmp_html, file = tmp_png, vwidth = 1100, vheight = 700, zoom = 2, delay = 2)
    knitr::include_graphics(tmp_png)
  } else {
    map_data %>%
      arrange(desc(n_participants)) %>%
      select(commune, n_participants) %>%
      knitr::kable(col.names = c("Commune", "Effectif (Q1)"))
  }
}
```

### Langue des questionnaires (français vs créole)

```{r}
#| label: fig-langue-q1
#| fig-cap: "Langue du questionnaire (Q1)"
lang_dist <- data %>%
  filter(langue_q1 %in% c("Français", "Créole")) %>%
  count(langue_q1, name = "n") %>%
  mutate(p = n / sum(n)) %>%
  # Inversion de l’ordre pour le graphique (Créole en premier)
  arrange(desc(langue_q1))

ggplot(lang_dist, aes(x = "", y = n, fill = langue_q1)) +
  geom_col(width = 1, color = "white", linewidth = 0.6) +
  coord_polar(theta = "y") +
  geom_text(
    aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")),
    position = position_stack(vjust = 0.5),
    size = 4
  ) +
  scale_fill_manual(values = c("Français" = col_lang_fr, "Créole" = col_lang_cr)) +
  labs(title = "Langue du questionnaire (Q1)", x = NULL, y = NULL, fill = NULL) +
  theme_article(base_size = 12) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.grid = element_blank())
```

```{r}
#| label: fig-langue-q1-bar
#| fig-cap: "Langue du questionnaire Q1 (barplot)"
ggplot(lang_dist, aes(x = langue_q1, y = n, fill = langue_q1)) +
  geom_col(width = 0.6, color = "white", linewidth = 0.4) +
  geom_text(aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")), vjust = -0.4, size = 4) +
  scale_fill_manual(values = c("Français" = col_lang_fr, "Créole" = col_lang_cr)) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  labs(title = "Langue du questionnaire (Q1)", x = NULL, y = "Effectif", fill = NULL) +
  theme_article(base_size = 12) +
  theme(legend.position = "none")
```

```{r}
#| label: fig-langue-q2
#| fig-cap: "Langue du questionnaire (Q2) et attrition"
# Calcul des effectifs pour le graphique Q2
lang_counts_q2 <- data_matched %>%
  filter(langue_q2 %in% c("Français", "Créole")) %>%
  count(langue_q2, name = "n") %>%
  rename(langue = langue_q2)

# Nombre de non-appariés
n_unmatched <- n_q1 - n_q2_matched

# Données pour le graphique
plot_data_q2 <- lang_counts_q2 %>%
  tibble::add_row(langue = "Non apparié", n = n_unmatched) %>%
  mutate(
    p = n / sum(n),
    # Ordonner les catégories pour le graphique (avec inversion pour les langues)
    langue = factor(langue, levels = c("Créole", "Français", "Non apparié"))
  )

# Création du graphique
ggplot(plot_data_q2, aes(x = "", y = n, fill = langue)) +
  geom_col(width = 1, color = "white", linewidth = 0.6) +
  coord_polar(theta = "y") +
  geom_text(
    aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")),
    position = position_stack(vjust = 0.5),
    size = 3.5 # Slightly smaller text to fit
  ) +
  scale_fill_manual(values = c("Français" = col_lang_fr, "Créole" = col_lang_cr, "Non apparié" = "grey75")) +
  labs(title = "Langue du questionnaire (Q2) et non-appariés", x = NULL, y = NULL, fill = NULL) +
  theme_article(base_size = 12) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.grid = element_blank())
```

```{r}
#| label: fig-langue-q2-bar
#| fig-cap: "Langue du questionnaire Q2 et non-appariés (barplot)"
ggplot(plot_data_q2, aes(x = langue, y = n, fill = langue)) +
  geom_col(width = 0.6, color = "white", linewidth = 0.4) +
  geom_text(aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")), vjust = -0.4, size = 3.5) +
  scale_fill_manual(values = c("Français" = col_lang_fr, "Créole" = col_lang_cr, "Non apparié" = "grey75")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  labs(title = "Langue du questionnaire (Q2) et non-appariés", x = NULL, y = "Effectif", fill = NULL) +
  theme_article(base_size = 12) +
  theme(legend.position = "none")
```

### Appariement

```{r}
knitr::kable(tibble(
  `Indicateur` = c("Répondantes Q1 (total)", "Réponses Q2 (total)", "Paires Q1–Q2 (appariées)", "Q1 non appariées"),
  `Effectif` = c(n_q1, n_q2_total, n_q2_matched, n_q1 - n_q2_matched)
), align = "l")
```

### Proportion d’appariement (Q1 → Q2)

```{r}
match_dist <- data %>%
  transmute(status = ifelse(has_match, "Appariées", "Non appariées")) %>%
  count(status, name = "n") %>%
  mutate(p = n / sum(n))

ggplot(match_dist, aes(x = "", y = n, fill = status)) +
  geom_col(width = 1, color = "white", linewidth = 0.6) +
  coord_polar(theta = "y") +
  geom_text(aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")),
            position = position_stack(vjust = 0.5), size = 4) +
  scale_fill_manual(values = c("Appariées" = col_post, "Non appariées" = "grey75")) +
  labs(title = "Proportion d'appariement", x = NULL, y = NULL, fill = NULL) +
  theme_article(base_size = 12) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(), panel.grid = element_blank())
```

```{r}
#| label: fig-appariement-bar
#| fig-cap: "Proportion d'appariement (barplot)"
ggplot(match_dist, aes(x = status, y = n, fill = status)) +
  geom_col(width = 0.6, color = "white", linewidth = 0.4) +
  geom_text(aes(label = paste0(n, " (", scales::percent(p, accuracy = 0.1), ")")), vjust = -0.4, size = 4) +
  scale_fill_manual(values = c("Appariées" = col_post, "Non appariées" = "grey75")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  labs(title = "Proportion d'appariement", x = NULL, y = "Effectif", fill = NULL) +
  theme_article(base_size = 12) +
  theme(legend.position = "none")
```

Ici, **`r n_q2_matched`/`r n_q1`** réponses du Q1 sont appariées (soit `r scales::percent(n_q2_matched/n_q1, accuracy = 0.1)`), et l’on retrouve **`r n_q2_matched`/`r n_q2_total`** réponses du Q2 (soit `r scales::percent(n_q2_matched/n_q2_total, accuracy = 0.1)`). 

L’analyse principale avant–après porte sur l’échantillon “Appariées”.


### Schéma de flux (effectifs)

```{r}
flow_tbl <- tibble(
  `Étape` = c(
    "Q1 (total)",
    "Q2 (total, non apparié)",
    "Paires Q1–Q2 (analysées)",
    "Q1 non appariées (perdues au Q2)"
  ),
  `Effectif` = c(
    n_q1,
    n_q2_total,
    n_q2_matched,
    n_q1 - n_q2_matched
  )
) %>%
  mutate(
    `Proportion` = c(
      "100%",
      "—",
      scales::percent(n_q2_matched / n_q1, accuracy = 0.1),
      scales::percent((n_q1 - n_q2_matched) / n_q1, accuracy = 0.1)
    )
  )

knitr::kable(flow_tbl, align = "l")
```

```{r}
#| label: fig-flowchart
#| fig-width: 6
#| fig-height: 4
#| fig-cap: "Diagramme de flux simplifié"
flow_df <- tibble(
  x = c(0, 0, -1, 1),
  y = c(3, 2, 1, 1),
  label = c(
    paste0("Q1 : ", n_q1, " répondantes"),
    paste0("Appariement\n(âge + commune)"),
    paste0("Non appariées\n", n_q1 - n_q2_matched, " (", scales::percent((n_q1 - n_q2_matched) / n_q1, accuracy = 0.1), ")"),
    paste0("Paires Q1–Q2\n", n_q2_matched, " (", scales::percent(n_q2_matched / n_q1, accuracy = 0.1), ")")
  ),
  fill_col = c(col_pre, "grey90", col_neg, col_post)
)

ggplot(flow_df) +
  geom_rect(aes(xmin = x - 0.8, xmax = x + 0.8, ymin = y - 0.35, ymax = y + 0.35, fill = fill_col),
            color = "grey40", linewidth = 0.5, alpha = 0.2) +
  geom_text(aes(x = x, y = y, label = label), size = 3.5, lineheight = 0.9) +
  geom_segment(aes(x = 0, y = 2.65, xend = 0, yend = 2.35), arrow = arrow(length = unit(0.15, "cm")), color = "grey40") +
  geom_segment(aes(x = -0.3, y = 1.65, xend = -0.8, yend = 1.35), arrow = arrow(length = unit(0.15, "cm")), color = "grey40") +
  geom_segment(aes(x = 0.3, y = 1.65, xend = 0.8, yend = 1.35), arrow = arrow(length = unit(0.15, "cm")), color = "grey40") +
  scale_fill_identity() +
  theme_void() +
  labs(title = "Flux des participantes")
```

Interprétation : Même interprétaion que le camembert précédent. Des patientes qui ont répondu au 2ème questionnaire, `r n_q2_matched`/`r n_q2_total` réponses ont été appariées (soit `r scales::percent(n_q2_matched/n_q2_total, accuracy = 0.1)`).

### Attrition selon l'âge (Q1 appariées vs Q1 non appariées)

= Y a-t-il plus de pertes au suivi (Q2 manquant) dans certaines tranches d’âge ?

-   Via un test du chi2 d’indépendance entre la tranche d’âge et le statut d’appariement (Q1 avec ou sans Q2) : p-value > 0.9 donc pas d'impact évident de l’âge sur l’attrition.

-   Visuellement : pas d'impact de l'âge sur l’attrition non plus.

**Graphique pas obligatoire** : en gros y a pas de différence des "perdus de vue" selon l'âge.

```{r}
age_attr <- data %>%
  filter(age_group != "Inconnu") %>%
  count(age_group, has_match, name = "n") %>%
  group_by(age_group) %>%
  mutate(p = n / sum(n)) %>%
  ungroup() %>%
  mutate(status = ifelse(has_match, "Appariées (ont Q2)", "Non appariées (pas Q2)"))

age_attr_data <- data %>% filter(age_group != "Inconnu") %>% mutate(age_group = droplevels(age_group))
age_attr_tab <- with(age_attr_data, table(age_group, has_match))

# Utiliser Fisher si effectifs faibles, sinon chi2
if (any(age_attr_tab < 5)) {
  chisq_age_attr <- fisher.test(age_attr_tab, simulate.p.value = TRUE, B = 2000)
} else {
  chisq_age_attr <- chisq.test(age_attr_tab)
}
```

```{r}
ggplot(age_attr, aes(x = age_group, y = p, fill = status)) +
  geom_col(position = "fill", color = "white", linewidth = 0.4) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  scale_fill_manual(values = c("Appariées (ont Q2)" = col_post, "Non appariées (pas Q2)" = "grey75")) +
  labs(
    x = NULL,
    y = "Proportion",
    fill = NULL,
    title = "Attrition selon l'âge : proportion de Q1 avec ou sans Q2"
  ) +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Même graphique mais avec les effectifs en ordonnées :

```{r}
ggplot(age_attr, aes(x = age_group, y = n, fill = status)) +
  geom_col(position = "dodge", color = "white", linewidth = 0.4) +
  scale_y_continuous(labels = scales::comma_format()) +
  scale_fill_manual(values = c("Appariées (ont Q2)" = col_post, "Non appariées (pas Q2)" = "grey75")) +
  labs(
    x = NULL,
    y = "Effectif",
    fill = NULL,
    title = "Attrition selon l'âge : effectifs de Q1 avec ou sans Q2"
  ) +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```


## Résultats

### Résultats clés (lecture rapide)

```{r}
data_matched_key <- data_matched %>%
  mutate(
    score_pre = score_pre_calc,
    score_post = score_post_calc,
    score_diff = score_post - score_pre
  )

key_tbl <- tibble(
  `n (paires)` = nrow(data_matched_key),
  `Moyenne Q1 (/20)` = mean(data_matched_key$score_pre, na.rm = TRUE),
  `Moyenne Q2 (/20)` = mean(data_matched_key$score_post, na.rm = TRUE),
  `Gain moyen (Q2−Q1)` = mean(data_matched_key$score_diff, na.rm = TRUE),
  `Proportion gain >= 3` = mean(data_matched_key$score_diff >= 3, na.rm = TRUE)
) %>%
  mutate(
    `Moyenne Q1 (/20)` = round(`Moyenne Q1 (/20)`, 2),
    `Moyenne Q2 (/20)` = round(`Moyenne Q2 (/20)`, 2),
    `Gain moyen (Q2−Q1)` = round(`Gain moyen (Q2−Q1)`, 2),
    `Proportion gain >= 3` = scales::percent(`Proportion gain >= 3`, accuracy = 0.1)
  )

knitr::kable(key_tbl, align = "l")
```

Le gain moyen entre les groupes Q1 et Q2 (appariées) est à `r fmt_num(mean(data_matched_key$score_diff, na.rm = TRUE), 2)` points, et la proportion de participantes avec un gain >= 3 points est de `r scales::percent(mean(data_matched_key$score_diff >= 3, na.rm = TRUE), accuracy = 0.1)`.

### Biais de sélection potentiel : Q1 appariées vs Q1 non appariées

Idée : comparer les participantes ayant répondu au premier questionnaire puis appariées aux patientes ayant répondu au 2ème questionnaire, par rapport aux patientes ayant répondu au 1er questionnaire mais n'ayant pas été appariées.

```{r}
sel_tbl <- data %>%
  mutate(groupe = ifelse(has_match, "Q1 appariées (ont un Q2)", "Q1 non appariées (pas de Q2)")) %>%
  group_by(groupe) %>%
  summarise(
    n = n(),
    mean_q1 = mean(score_pre_calc, na.rm = TRUE),
    sd_q1 = sd(score_pre_calc, na.rm = TRUE),
    median_q1 = median(score_pre_calc, na.rm = TRUE),
    iqr_q1 = IQR(score_pre_calc, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

knitr::kable(sel_tbl, align = "l")
```

```{r}
tt_sel <- t.test(score_pre_calc ~ has_match, data = data)

sel_test_tbl <- tibble(
  `Test` = "Welch t-test (Q1 appariées vs non appariées)",
  `t` = round(tt_sel$statistic, 2),
  `df` = round(tt_sel$parameter, 1),
  `p-value` = fmt_p(tt_sel$p.value),
  `IC95% diff.` = paste0("[", round(tt_sel$conf.int[1], 2), " ; ", round(tt_sel$conf.int[2], 2), "]")
)

knitr::kable(sel_test_tbl, align = "l")
```

```{r}
ggplot(
  data %>% mutate(groupe = ifelse(has_match, "Q1 appariées", "Q1 non appariées")),
  aes(x = groupe, y = score_pre_calc, fill = groupe)
) +
  geom_boxplot(width = 0.55, outlier.alpha = 0.2) +
  geom_jitter(width = 0.08, alpha = 0.25, size = 1) +
  scale_fill_manual(values = c("Q1 appariées" = col_pre, "Q1 non appariées" = "grey75")) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = NULL, y = "Score global Q1 (/20)", title = "Comparaison des scores Q1 : appariées vs non appariées") +
  theme_article(base_size = 12) +
  theme(legend.position = "none")
```

Interprétation : si le score initial Q1 est différent entre appariées et non appariées (tests ci-dessus), cela suggère un **biais de sélection**. Dans ce cas, utiliser la moyenne Q1 “totale” pour estimer un gain (en la comparant à la moyenne Q2) serait **non valide**, car cela comparerait des populations différentes.

::: {.callout-important title="Ce que cela signifie concrètement"}
Les tests et le graphique confirment que les participantes qui ont répondu au Q2 ("appariées") avaient déjà un **score initial significativement plus élevé**.

-   **Score Q1 moyen (appariées) :** `r fmt_num(mean(data$score_pre_calc[data$has_match], na.rm = TRUE))`
-   **Score Q1 moyen (non appariées) :** `r fmt_num(mean(data$score_pre_calc[!data$has_match], na.rm = TRUE))`

Il serait donc **méthodologiquement faux** de comparer la moyenne de *tous* les Q2 à la moyenne de *tous* les Q1. La seule méthode correcte est l'analyse **appariée**, qui mesure l'évolution au sein de chaque personne ayant complété les deux questionnaires.

Interprétation possible (à discuter) : si les participantes non appariées avaient eu un score initial très élevé, on pourrait suspecter qu’elles avaient moins ressenti le besoin de répondre au second questionnaire. **Ici, c’est plutôt l’inverse** (les appariées ont un score initial moyen plus élevé), ce qui suggère plutôt que les participantes les plus informées (ou les plus motivées) ont davantage répondu au Q2.
:::


### Mise en évidence de la moyenne initiale (Q1)

```{r}
baseline_all_ci <- t.test(data$score_pre_calc)$conf.int
baseline_matched_ci <- t.test(data_matched$score_pre)$conf.int

baseline_tbl <- tibble(
  `Échantillon` = c("Q1 total (avant appariement)", "Q1 apparié (paires complètes)"),
  `n` = c(nrow(data), nrow(data_matched)),
  `Moyenne initiale (Q1, /20)` = c(mean(data$score_pre_calc), mean(data_matched$score_pre)),
  `Écart-type (Q1)` = c(sd(data$score_pre_calc), sd(data_matched$score_pre)),
  `IC95% bas (Q1)` = c(baseline_all_ci[1], baseline_matched_ci[1]),
  `IC95% haut (Q1)` = c(baseline_all_ci[2], baseline_matched_ci[2])
) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

knitr::kable(baseline_tbl, align = "l")
```

Interprétation : la moyenne initiale du score global (Q1) est de **`r fmt_num(mean(data$score_pre_calc, na.rm = TRUE), 2)`/20** avant appariement, et de **`r fmt_num(mean(data_matched$score_pre, na.rm = TRUE), 2)`/20** dans l’échantillon apparié, ce qui suggère une marge de progression limitée vers 20/20 (effet plafond possible).

```{r}
age_q1 <- data %>%
  count(age_group, name = "n_q1") %>%
  mutate(p_q1 = n_q1 / sum(n_q1))

age_q2 <- data_matched %>%
  count(age_group, name = "n_q2") %>%
  mutate(p_q2 = n_q2 / sum(n_q2))

age_tbl <- full_join(age_q1, age_q2, by = "age_group") %>%
  mutate(
    n_q1 = tidyr::replace_na(n_q1, 0L),
    p_q1 = tidyr::replace_na(p_q1, 0),
    n_q2 = tidyr::replace_na(n_q2, 0L),
    p_q2 = tidyr::replace_na(p_q2, 0),
    Q1 = paste0(n_q1, " (", scales::percent(p_q1, accuracy = 0.1), ")"),
    Q2 = paste0(n_q2, " (", scales::percent(p_q2, accuracy = 0.1), ")")
  ) %>%
  select(`Âge` = age_group, Q1, Q2)

knitr::kable(age_tbl, align = "l")
```

Interprétation : ce tableau décrit la distribution des tranches d’âge dans l’échantillon Q1 (colonne Q1) et dans l’échantillon ayant répondu au second temps (colonne Q2).


### Score global au Q2 (Q2 total)

```{r}
q2_desc <- q2_scores %>%
  summarise(
    `n (Q2)` = n(),
    `Moyenne Q2 (/20)` = mean(score_q2_total_reported),
    `Min (/20)` = min(score_q2_total_reported),
    `Max (/20)` = max(score_q2_total_reported)
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

knitr::kable(q2_desc, align = "l")
```

Interprétation : ce tableau décrit le score global observé au Q2 dans l'ensemble des répondantes au second questionnaire (n = `r n_q2_total`). Cette moyenne ne doit pas être utilisée pour calculer un "gain avant/après", car le Q1 correspondant n'est pas disponible pour toutes les répondantes du Q2 et la comparaison avant/après doit se faire sur des données appariées (mêmes participantes au Q1 et au Q2).

## Résultats principaux

### Appariement et population analysée

::: {.callout-note icon="false"}
## Principaux résultats en langage simple (échantillon apparié, n = `r nrow(data_matched)`)

1.  **L'information a-t-elle amélioré les connaissances ?**  
    **Oui.** En moyenne, les participantes ont gagné **`r fmt_num(gain_mean_simple, 2)` points** sur 20 après information. Cette amélioration est **`r sig_txt(tt_simple$p.value, alpha)`** (t-test apparié unilatéral : p = `r fmt_p(tt_simple$p.value)`), ce qui veut dire qu'il est très improbable qu'elle soit due au hasard.

2.  **L'amélioration est-elle "cliniquement pertinente" (gain d'au moins 3 points) ?**  
    **En moyenne : presque.** Le gain moyen est de **`r fmt_num(gain_mean_simple, 2)`** points, donc **très proche** du seuil de 3 points. L'IC95% bilatéral du gain moyen est **[`r fmt_num(tt_ci_simple$conf.int[1], 2)` ; `r fmt_num(tt_ci_simple$conf.int[2], 2)`]**, ce qui est compatible avec un gain moyen autour de 3. En revanche, **`r scales::percent(prop_ge_3_simple, accuracy = 0.1)`** des participantes ont atteint ou dépassé **3 points** de gain.

3.  **Pourquoi le gain moyen n'est-il pas plus élevé ?**  
    Principalement à cause d'un **effet plafond** : le score de départ était déjà élevé (moyenne Q1 = **`r fmt_num(baseline_mean_simple, 2)`/20**). Quand on part déjà haut, il est mathématiquement plus difficile de gagner beaucoup de points.

4.  **Y a-t-il des différences selon l'âge ?**  
    **`r ifelse(kw_age_simple$p.value < alpha, "Oui, possiblement.", "Non, pas de manière évidente.")`** La comparaison des gains selon les tranches d’âge est `r sig_txt(kw_age_simple$p.value, alpha)` (Kruskal–Wallis : p = `r fmt_p(kw_age_simple$p.value)`).

**Conclusion simple :** l’information améliore les connaissances en moyenne ; le gain moyen est très proche de 3 points, et le niveau initial déjà élevé limite la marge de progression.
:::


```{r}
data_matched_sens <- data_matched %>%
  filter(abs(diff_pre_vs_reported) <= 1e-6, abs(diff_post_vs_reported) <= 1e-6)

tt_all <- t.test(data_matched$score_post, data_matched$score_pre, paired = TRUE, alternative = "two.sided")
tt_sens <- t.test(data_matched_sens$score_post, data_matched_sens$score_pre, paired = TRUE, alternative = "two.sided")

sens_tbl <- tibble(
  `Analyse` = c("Principale (toutes paires)", "Sensibilité (sans discordance)"),
  `n` = c(nrow(data_matched), nrow(data_matched_sens)),
  `Gain moyen` = c(mean(data_matched$score_diff), mean(data_matched_sens$score_diff)),
  `IC95% gain` = c(
    paste0("[", round(tt_all$conf.int[1], 2), " ; ", round(tt_all$conf.int[2], 2), "]"),
    paste0("[", round(tt_sens$conf.int[1], 2), " ; ", round(tt_sens$conf.int[2], 2), "]")
  ),
  `p t-test (bilatéral)` = c(fmt_p(tt_all$p.value), fmt_p(tt_sens$p.value))
) %>%
  mutate(`Gain moyen` = round(`Gain moyen`, 2))

knitr::kable(sens_tbl, align = "l")
```

```{r}
# --- Scoring par question (préparé ici pour pouvoir l'utiliser plus tôt dans le rapport) ---
scored_list <- lapply(seq_len(nrow(key)), function(i) {
  q <- key[i, ]
  pre <- vapply(
    data_matched[[q$q1_col]],
    score_response,
    numeric(1),
    q$correct_options[[1]],
    q$points[[1]]
  )
  post <- vapply(
    data_matched[[q$q2_col]],
    score_response,
    numeric(1),
    q$correct_options[[1]],
    q$points[[1]]
  )

  tibble(
    participant_id = data_matched$Q1_row,
    age_group = data_matched$age_group,
    id = q$id,
    label = q$label,
    max_points = q$max_points,
    score_pre = pre,
    score_post = post,
    score_diff = post - pre,
    full_pre = pre >= q$max_points,
    full_post = post >= q$max_points
  )
})

by_question <- bind_rows(scored_list)
```



### Impact global sur le score

#### Résumé visuel des résultats clés

```{r}
#| label: plot_key_summary_card
#| fig-width: 8
#| fig-height: 4

# Calculer les 4 métriques clés
summary_vals <- data_matched %>%
  summarise(
    score_pre = mean(score_pre),
    score_post = mean(score_post),
    score_diff = mean(score_diff),
    prop_gain_3 = mean(score_diff >= 3)
  )

# Créer un dataframe pour le plotting
plot_data <- tibble(
  metric = c("Score initial\n(moyenne)", "Score final\n(moyenne)", "Gain moyen\n(Q2 - Q1)", "Proportion avec\ngain >= 3 points"),
  value = c(
    sprintf("%.1f / 20", summary_vals$score_pre),
    sprintf("%.1f / 20", summary_vals$score_post),
    sprintf("+%.1f pts", summary_vals$score_diff),
    sprintf("%.1f%%", 100 * summary_vals$prop_gain_3)
  ),
  x = rep(c(0.25, 0.75), 2),
  y = c(0.75, 0.75, 0.25, 0.25),
  color = c(col_pre, col_post, col_post, col_post)
)

# Créer le graphique
ggplot(plot_data, aes(x = x, y = y)) +
  # Cartes de fond
  geom_rect(aes(xmin = x - 0.2, xmax = x + 0.2, ymin = y - 0.2, ymax = y + 0.2, fill = color),
            alpha = 0.1, color = "grey80", linetype = "dotted") +
  # Texte de la métrique
  geom_text(aes(label = metric), vjust = 1.5, size = 5, color = "grey30") +
  # Texte de la valeur
  geom_text(aes(label = value, color = color), size = 12, fontface = "bold") +
  # Thème
  scale_fill_identity() +
  scale_color_identity() +
  theme_void() +
  labs(title = "L'essentiel des résultats en un coup d'œil") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, color = "grey40", face = "italic"))
```

#### Données longues (pour graphiques)

```{r}
data_matched_long <- data_matched %>%
  select(Q1_row, score_pre, score_post) %>%
  pivot_longer(
    cols = c(score_pre, score_post),
    names_to = "time",
    values_to = "score"
  ) %>%
  mutate(
    id = as.character(Q1_row),
    time = recode(time, score_pre = "Avant (Q1)", score_post = "Après (Q2)"),
    time = factor(time, levels = c("Avant (Q1)", "Après (Q2)"))
  )
```

### Comparaison des moyennes (table)

```{r}
data_matched %>%
  select(score_pre, score_post, score_diff) %>%
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ± {sd}"),
    digits = all_continuous() ~ 2,
    missing = "no"
  ) %>%
  modify_header(label ~ "**Mesure**", stat_0 ~ "**Participants appariés**") %>%
  bold_labels()
```

Interprétation (table des moyennes) : la ligne `score_diff` résume directement l’effet moyen de l’intervention (gain = Q2 - Q1). L’écart-type informe sur l’hétérogénéité des réponses individuelles.

### Distribution des scores initiaux (Q1)

```{r}
ggplot(data_matched, aes(x = score_pre)) +
  geom_histogram(binwidth = 1, boundary = 0, closed = "left", fill = col_pre, alpha = 0.9, color = "white") +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = "Score initial (Q1)", y = "Fréquence", title = "Distribution du score global initial (Q1)") +
  theme_article(base_size = 12)
```

Interprétation : cet histogramme décrit le niveau de connaissances initial global et permet d’apprécier la dispersion, ainsi qu’un éventuel effet plafond si de nombreux scores sont proches de 20.

#### Boxplots côte à côte (score global)

```{r}
ggplot(data_matched_long, aes(x = time, y = score, fill = time)) +
  geom_boxplot(width = 0.55, outlier.alpha = 0.2) +
  geom_jitter(width = 0.08, alpha = 0.35, size = 1) +
  scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = NULL, y = "Score global") +
  theme_minimal(base_size = 13) +
  theme(legend.position = "none")
```

Interprétation (boxplots) : on observe un déplacement global vers des scores plus élevés après l’information. La médiane passe de `r round(median(data_matched$score_pre), 2)` (Q1) à `r round(median(data_matched$score_post), 2)` (Q2), et l’intervalle interquartile se déplace dans le même sens.

#### Diagramme spaghetti (évolution individuelle)

```{r}
ggplot(data_matched_long, aes(x = time, y = score, group = id)) +
  geom_line(alpha = 0.18, linewidth = 0.5, color = "grey35") +
  geom_point(aes(color = time), alpha = 0.6, size = 1.2) +
  stat_summary(aes(group = 1), fun = mean, geom = "line", linewidth = 1.1, color = "grey25") +
  stat_summary(aes(color = time), fun = mean, geom = "point", size = 2.4) +
  scale_color_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = NULL, y = "Score global") +
  theme_minimal(base_size = 13)
```

```{r}
n_gain <- sum(data_matched$score_diff > 0, na.rm = TRUE)
n_loss <- sum(data_matched$score_diff < 0, na.rm = TRUE)
n_tie <- sum(data_matched$score_diff == 0, na.rm = TRUE)
```

Interprétation (spaghetti) : la majorité des trajectoires individuelles monte (gain > 0 : `r n_gain` participantes), avec `r n_loss` baisses et `r n_tie` stabilités. La tendance moyenne est à l’augmentation entre Q1 et Q2.

Ce graphique raconte aussi l'histoire de chaque participante. Chaque ligne grise fine représente la trajectoire d'une personne, et la ligne noire épaisse la **tendance moyenne** du groupe. On voit que la grande majorité des lignes **montent**, ce qui suggère un effet positif global de l'intervention, qui va maintenant être formalisé par les tests statistiques.

#### Diagramme spaghetti coloré (par direction du gain)

Ce graphique reprend le diagramme spaghetti ci-dessus, mais chaque trajectoire est colorée selon la direction du changement : vert pour les améliorations, rouge pour les diminutions, gris pour les stabilités.

```{r}
#| label: plot_spaghetti_colored
#| fig-width: 8
#| fig-height: 6
data_matched_colored <- data_matched %>%
  mutate(
    direction = case_when(
      score_diff > 0 ~ "Amélioration",
      score_diff < 0 ~ "Diminution",
      TRUE ~ "Stable"
    ),
    direction = factor(direction, levels = c("Amélioration", "Stable", "Diminution"))
  )

data_colored_long <- data_matched_colored %>%
  select(Q1_row, score_pre, score_post, direction) %>%
  pivot_longer(
    cols = c(score_pre, score_post),
    names_to = "time",
    values_to = "score"
  ) %>%
  mutate(
    time = recode(time, score_pre = "Avant (Q1)", score_post = "Après (Q2)"),
    time = factor(time, levels = c("Avant (Q1)", "Après (Q2)"))
  )

ggplot(data_colored_long, aes(x = time, y = score, group = Q1_row, color = direction)) +
  geom_line(alpha = 0.35, linewidth = 0.5) +
  geom_point(alpha = 0.5, size = 1) +
  stat_summary(aes(group = 1, color = NULL), fun = mean, geom = "line",
               linewidth = 1.3, color = "grey15", linetype = "solid") +
  stat_summary(aes(group = 1, color = NULL), fun = mean, geom = "point",
               size = 3, color = "grey15") +
  scale_color_manual(
    values = c("Amélioration" = col_post, "Stable" = col_neutral, "Diminution" = col_neg),
    name = NULL
  ) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(
    x = NULL,
    y = "Score global (/20)",
    title = "Trajectoires individuelles colorées par direction du gain",
    subtitle = paste0("Vert = amélioration (", n_gain, "), gris = stable (", n_tie, "), rouge = diminution (", n_loss, ")")
  ) +
  theme_article(base_size = 12)
```

#### Nuage de points Q1 vs Q2 (appariés)

```{r}
ggplot(data_matched, aes(x = score_pre, y = score_post)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey35") +
  geom_jitter(aes(color = case_when(
    score_diff > 0 ~ "Amélioration",
    score_diff < 0 ~ "Diminution",
    TRUE ~ "Stable"
  )), width = 0.12, height = 0.12, alpha = 0.65, size = 1.6) +
  scale_color_manual(
    values = c("Amélioration" = col_post, "Stable" = col_neutral, "Diminution" = col_neg),
    name = NULL
  ) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  coord_equal() +
  labs(
    x = "Score Q1 (/20)",
    y = "Score Q2 (/20)",
    title = "Scores individuels : Q1 vs Q2",
    subtitle = "Au-dessus de la diagonale : amélioration ; en dessous : diminution"
  ) +
  theme_article(base_size = 12)
```

Interprétation : ce graphique visualise directement l’évolution individuelle. Si la majorité des points est au-dessus de la diagonale, l’amélioration est majoritaire.

#### Waterfall plot des gains (Q2 − Q1)

```{r}
waterfall <- data_matched %>%
  mutate(score_diff = score_post - score_pre) %>%
  arrange(score_diff) %>%
  mutate(rank = row_number()) %>%
  mutate(direction = case_when(
    score_diff > 0 ~ "Gain > 0",
    score_diff < 0 ~ "Gain < 0",
    TRUE ~ "Gain = 0"
  ))

prop_ge3_wf <- mean(waterfall$score_diff >= 3, na.rm = TRUE)
n_ge3_wf <- sum(waterfall$score_diff >= 3, na.rm = TRUE)

ggplot(waterfall, aes(x = rank, y = score_diff, fill = direction)) +
  geom_col(width = 0.9) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey25") +
  geom_hline(yintercept = 3, linetype = "dotted", color = col_post, linewidth = 0.7) +
  annotate("text",
    x = nrow(waterfall) * 0.85, y = max(waterfall$score_diff) - 0.5,
    label = paste0(n_ge3_wf, "/", nrow(waterfall), " (", sprintf("%.1f%%", 100 * prop_ge3_wf), ")\ngain >= 3 pts"),
    size = 3.5, color = "grey25", fontface = "italic", hjust = 0.5
  ) +
  scale_fill_manual(values = c("Gain > 0" = col_post, "Gain = 0" = col_neutral, "Gain < 0" = col_neg)) +
  labs(
    x = "Participantes (triées par gain)",
    y = "Gain (Q2 − Q1)",
    fill = NULL,
    title = "Gains individuels triés (waterfall)",
    subtitle = "Ligne pointillée verte : seuil clinique de 3 points"
  ) +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Interprétation : ce graphique montre l’ampleur et la variabilité des gains. On visualise aussi la proportion de participantes dépassant le seuil de 3 points.

#### Gain en fonction du score initial (effet plafond)

```{r}
ggplot(data_matched, aes(x = score_pre, y = score_diff)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey25") +
  geom_hline(yintercept = 3, linetype = "dotted", color = "grey25") +
  geom_jitter(width = 0.12, height = 0.12, alpha = 0.55, size = 1.4, color = "grey25") +
  geom_smooth(method = "loess", se = TRUE, color = col_post, fill = col_post, alpha = 0.15) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(
    x = "Score initial Q1 (/20)",
    y = "Gain (Q2 − Q1)",
    title = "Gain selon le score initial",
    subtitle = "Tendance attendue : gain plus faible quand le score initial est déjà élevé"
  ) +
  theme_article(base_size = 12)
```

Interprétation : si la courbe diminue quand le score initial augmente, cela illustre l’effet plafond (moins de marge pour progresser quand on est déjà proche de 20/20).

#### Analyse et interprétation (avant/après)

Sur les participantes appariées ($n = `r nrow(data_matched)`$), le score moyen passe de **`r round(mean(data_matched$score_pre), 2)`** (avant) à **`r round(mean(data_matched$score_post), 2)`** (après), soit un gain moyen de **`r round(mean(data_matched$score_diff), 2)`** points.

Pourquoi on compare Q2 à la moyenne Q1 *appariée* (et pas à la moyenne Q1 “totale”) :

- Pour mesurer un effet “avant/après”, il faut comparer **les mêmes personnes** au temps 1 et au temps 2.
- La moyenne Q2 est calculée uniquement chez les participantes qui ont un Q2 (donc les **appariées**).
- Si on compare la moyenne Q2 (appariées) à la moyenne Q1 “totale” (appariées + non appariées), on compare en réalité **deux groupes différents**. La différence mélange alors l’effet potentiel de l’information avec un **biais de sélection** (par exemple : les participantes qui répondent au Q2 peuvent être, au départ, plus informées ou plus motivées).
- Dans ces données, cela se voit : la moyenne Q1 avant appariement (**`r fmt_num(mean(data$score_pre_calc, na.rm = TRUE), 2)`/20**) est différente de la moyenne Q1 chez les appariées (**`r fmt_num(mean(data_matched$score_pre, na.rm = TRUE), 2)`/20**). Utiliser la moyenne Q1 “totale” pour estimer le gain donnerait donc un gain artificiellement plus grand, qui ne correspond pas à une comparaison avant/après sur les mêmes personnes.
- On pourrait aussi être tenté d’utiliser la moyenne Q2 “totale” (toutes les répondantes au Q2, **`r fmt_num(mean(q2_scores$score_q2_total_reported, na.rm = TRUE), 2)`/20** sur `r n_q2_total` réponses, min = `r fmt_num(min(q2_scores$score_q2_total_reported, na.rm = TRUE), 2)`, max = `r fmt_num(max(q2_scores$score_q2_total_reported, na.rm = TRUE), 2)`), mais cela ne règle pas le problème : le calcul d’un gain nécessite de disposer de Q1 et Q2 **pour la même personne**.

Avec un seuil de pertinence clinique fixé à **3 points**, le gain moyen est **`r ifelse(mean(data_matched$score_diff) >= 3, "au-dessus", "très légèrement en dessous")`** de ce seuil (gain moyen = `r round(mean(data_matched$score_diff), 2)`, IC95% bilatéral = [`r round(tt_ci_simple$conf.int[1], 2)` ; `r round(tt_ci_simple$conf.int[2], 2)`]).

#### Test statistique (test t apparié / Student)

Le test principal ci-dessous est un **test t apparié** (Student) qui compare la moyenne des différences à 0 (après - avant). Par défaut, le test est unilatéral (après > avant).

On teste l'hypothèse d'une amélioration des scores après information.

```{r}
#| output: false
alternative <- "greater"
delta_clin <- 3
alpha <- 0.05

tt_two_sided <- t.test(
  data_matched$score_post,
  data_matched$score_pre,
  paired = TRUE,
  alternative = "two.sided"
)

tt <- t.test(
  data_matched$score_post,
  data_matched$score_pre,
  paired = TRUE,
  alternative = alternative
)

tt

data_matched %>%
  summarise(
    mean_diff = mean(score_diff),
    ci_low = tt_two_sided$conf.int[1],
    ci_high = tt_two_sided$conf.int[2],
    n = n()
  )
```

Interprétation (t-test apparié, données observées) : le gain moyen est de `r round(mean(data_matched$score_diff), 2)` points. Le test t apparié est `r sig_txt(tt$p.value, alpha)` (p = `r fmt_p(tt$p.value)`), en faveur d'une **augmentation** après intervention.

Interprétation (IC95% du gain moyen) : l’IC95% bilatéral du gain moyen est [`r round(tt_two_sided$conf.int[1], 2)`, `r round(tt_two_sided$conf.int[2], 2)`] points.

#### Tableau de synthèse (analyse principale)

Ce tableau résume les résultats principaux sur l’échantillon apparié. Les tests sont rapportés en **bilatéral** (lecture standard) et en **unilatéral** (après > avant, cohérent avec l’hypothèse attendue).

```{r}
main_tbl <- tibble(
  `n (paires)` = nrow(data_matched),
  `Moyenne Q1 (/20)` = mean(data_matched$score_pre),
  `Moyenne Q2 (/20)` = mean(data_matched$score_post),
  `Gain moyen (Q2−Q1)` = mean(data_matched$score_diff),
  `IC95% gain (bilatéral)` = paste0(
    "[",
    round(tt_two_sided$conf.int[1], 2),
    " ; ",
    round(tt_two_sided$conf.int[2], 2),
    "]"
  ),
  `p t-test (bilatéral)` = fmt_p(tt_two_sided$p.value),
  `p t-test (unilatéral)` = fmt_p(tt$p.value)
) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2)))

knitr::kable(main_tbl, align = "l")
```

```{r}
# Tableau compact (plus lisible en PDF)
main_tbl_compact <- tibble(
  `n (paires)` = nrow(data_matched),
  `Q1 (moyenne ± SD)` = paste0(round(mean(data_matched$score_pre), 2), " ± ", round(sd(data_matched$score_pre), 2)),
  `Q2 (moyenne ± SD)` = paste0(round(mean(data_matched$score_post), 2), " ± ", round(sd(data_matched$score_post), 2)),
  `Gain moyen` = round(mean(data_matched$score_diff), 2),
  `IC95% gain` = paste0("[", round(tt_two_sided$conf.int[1], 2), " ; ", round(tt_two_sided$conf.int[2], 2), "]"),
  `p t-test (bilat.)` = fmt_p(tt_two_sided$p.value)
)

knitr::kable(main_tbl_compact, align = "l")
```

#### Taille d'effet : d de Cohen

::: {.callout-note title="Qu'est-ce que le d de Cohen ?"}
Le **d de Cohen** est un indicateur de **taille d'effet** qui quantifie l'ampleur d'une différence entre deux mesures, **indépendamment de la taille de l'échantillon**. Contrairement à la p-value (qui dit seulement si l'effet est "probablement réel"), le d de Cohen dit **à quel point l'effet est grand**.

**Calcul :** pour des données appariées, $d = \frac{\bar{x}_{\text{gain}}}{\text{SD}_{\text{gain}}}$, c'est-à-dire le gain moyen divisé par l'écart-type des gains.

**Interprétation (conventions de Cohen, 1988) :**

| d | Interprétation |
|---|---|
| < 0,2 | Effet négligeable |
| 0,2 – 0,5 | Effet **petit** |
| 0,5 – 0,8 | Effet **moyen** |
| > 0,8 | Effet **grand** |

Ces seuils sont des repères conventionnels ; l'interprétation doit toujours tenir compte du contexte (ici, un QCM de connaissances avec effet plafond).
:::

```{r}
#| label: cohen_d
# Calcul du d de Cohen pour données appariées
mean_diff <- mean(data_matched$score_diff, na.rm = TRUE)
sd_diff <- sd(data_matched$score_diff, na.rm = TRUE)
n_pairs <- nrow(data_matched)
cohens_d <- mean_diff / sd_diff

# IC95% du d de Cohen (approximation)
se_d <- sqrt((1 / n_pairs) + (cohens_d^2 / (2 * n_pairs)))
d_ci_low <- cohens_d - 1.96 * se_d
d_ci_high <- cohens_d + 1.96 * se_d

# Interprétation automatique
d_interp <- dplyr::case_when(
  abs(cohens_d) < 0.2 ~ "négligeable",
  abs(cohens_d) < 0.5 ~ "petit",
  abs(cohens_d) < 0.8 ~ "moyen",
  TRUE ~ "grand"
)

d_tbl <- tibble(
  `d de Cohen` = round(cohens_d, 3),
  `IC95%` = paste0("[", round(d_ci_low, 3), " ; ", round(d_ci_high, 3), "]"),
  `Interprétation` = paste0("Effet ", d_interp),
  `Gain moyen` = round(mean_diff, 2),
  `SD du gain` = round(sd_diff, 2)
)

knitr::kable(d_tbl, align = "l")
```

Interprétation : le d de Cohen est de **`r round(cohens_d, 2)`** (IC95% : [`r round(d_ci_low, 2)` ; `r round(d_ci_high, 2)`]), ce qui correspond à un effet **`r d_interp`** selon les conventions de Cohen. Cela signifie que le gain moyen représente environ **`r round(cohens_d, 2)` écart-type** de la variabilité interindividuelle des gains. Dans le contexte d'une intervention éducative sur les connaissances (avec un effet plafond notable), cet effet `r d_interp` est à interpréter en tenant compte du fait que les scores initiaux étaient déjà élevés, limitant mécaniquement la marge de progression.

#### Gain relatif (% de la marge de progression possible)

::: {.callout-note title="Pourquoi le gain relatif ?"}
Le gain brut (Q2 − Q1) ne tient pas compte de la **marge de progression** de chaque participante. Une personne à 18/20 ne peut gagner que 2 points au maximum, alors qu'une personne à 10/20 peut en gagner 10. Le **gain relatif** exprime le gain réel en pourcentage de la marge théoriquement disponible : $\text{Gain relatif} = \frac{\text{Q2} - \text{Q1}}{20 - \text{Q1}} \times 100$. Cet indicateur neutralise l'effet plafond.
:::

```{r}
#| label: relative_gain
data_matched <- data_matched %>%
  mutate(
    margin = 20 - score_pre,
    relative_gain = ifelse(margin > 0, (score_diff / margin) * 100, NA_real_)
  )

rel_gain_summary <- data_matched %>%
  filter(!is.na(relative_gain)) %>%
  summarise(
    n = n(),
    mean_rel = mean(relative_gain),
    median_rel = median(relative_gain),
    sd_rel = sd(relative_gain),
    q1_rel = quantile(relative_gain, 0.25),
    q3_rel = quantile(relative_gain, 0.75)
  )

rel_gain_tbl <- tibble(
  `n` = rel_gain_summary$n,
  `Gain relatif moyen` = paste0(round(rel_gain_summary$mean_rel, 1), "%"),
  `Médiane` = paste0(round(rel_gain_summary$median_rel, 1), "%"),
  `IQR` = paste0("[", round(rel_gain_summary$q1_rel, 1), "% ; ", round(rel_gain_summary$q3_rel, 1), "%]")
)

knitr::kable(rel_gain_tbl, align = "l")
```

```{r}
#| label: plot_relative_gain
#| fig-width: 8
#| fig-height: 5
ggplot(data_matched %>% filter(!is.na(relative_gain)), aes(x = score_pre, y = relative_gain)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey25") +
  geom_jitter(aes(color = case_when(
    relative_gain > 0 ~ "Gain",
    relative_gain < 0 ~ "Perte",
    TRUE ~ "Stable"
  )), width = 0.15, height = 0, alpha = 0.6, size = 1.6) +
  geom_smooth(method = "loess", se = TRUE, color = "grey25", fill = "grey80", alpha = 0.2) +
  scale_color_manual(
    values = c("Gain" = col_post, "Perte" = col_neg, "Stable" = col_neutral),
    name = NULL
  ) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(
    x = "Score initial Q1 (/20)",
    y = "Gain relatif (%)",
    title = "Gain relatif selon le score initial",
    subtitle = "Le gain relatif neutralise l'effet plafond en rapportant le gain à la marge disponible"
  ) +
  theme_article(base_size = 12)
```

Interprétation : en moyenne, les participantes ont comblé **`r round(rel_gain_summary$mean_rel, 1)`%** de leur marge de progression théorique (médiane : `r round(rel_gain_summary$median_rel, 1)`%). Ce chiffre est plus informatif que le gain brut car il tient compte du fait que les participantes avec un score initial élevé avaient mécaniquement moins de marge pour s'améliorer.

#### Distribution des gains (Q2 − Q1)

```{r}
#| label: plot_gain_distribution
#| fig-width: 8
#| fig-height: 5
gain_mean_hist <- mean(data_matched$score_diff, na.rm = TRUE)

ggplot(data_matched, aes(x = score_diff, fill = case_when(
  score_diff > 0 ~ "Gain",
  score_diff < 0 ~ "Perte",
  TRUE ~ "Stable"
))) +
  geom_histogram(binwidth = 1, boundary = 0, closed = "left", alpha = 0.85, color = "white") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey25", linewidth = 0.6) +
  geom_vline(xintercept = gain_mean_hist, linetype = "solid", color = "grey15", linewidth = 0.8) +
  geom_vline(xintercept = 3, linetype = "dotted", color = col_post, linewidth = 0.7) +
  annotate("text", x = gain_mean_hist + 0.3, y = Inf, vjust = 1.5,
           label = paste0("Moyenne = ", round(gain_mean_hist, 1)),
           size = 3.2, color = "grey15", fontface = "bold") +
  annotate("text", x = 3.3, y = Inf, vjust = 3,
           label = "Seuil clinique (3 pts)", size = 3, color = col_post, fontface = "italic") +
  scale_fill_manual(
    values = c("Gain" = col_post, "Stable" = col_neutral, "Perte" = col_neg),
    name = NULL
  ) +
  scale_x_continuous(breaks = seq(-10, 20, 2)) +
  labs(
    x = "Gain individuel (Q2 − Q1)",
    y = "Fréquence",
    title = paste0("Distribution des gains (n = ", nrow(data_matched), " paires)")
  ) +
  theme_article(base_size = 12)
```

Interprétation : cette distribution aide à visualiser l'hétérogénéité des réponses individuelles (certaines participantes progressent beaucoup, d'autres peu, et quelques-unes diminuent). Les barres vertes (gains), grises (stabilité) et rouges (pertes) permettent de voir immédiatement la répartition. La ligne pleine indique la moyenne, la ligne pointillée verte le seuil clinique de 3 points.

#### Proportion améliorée / stable / diminuée

```{r}
trend_tbl <- data_matched %>%
  mutate(
    tendance = case_when(
      score_diff > 0 ~ "Amélioration",
      score_diff == 0 ~ "Stable",
      TRUE ~ "Diminution"
    ),
    tendance = factor(tendance, levels = c("Diminution", "Stable", "Amélioration"))
  ) %>%
  count(tendance, name = "n") %>%
  mutate(p = n / sum(n))

knitr::kable(
  trend_tbl %>% mutate(p = scales::percent(p, accuracy = 0.1)),
  align = "l"
)
```

```{r}
ggplot(trend_tbl, aes(x = tendance, y = p, fill = tendance)) +
  geom_col(width = 0.75) +
  geom_text(aes(label = scales::percent(p, accuracy = 0.1)), vjust = -0.4, size = 4) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  scale_fill_manual(values = c("Diminution" = col_neg, "Stable" = col_neutral, "Amélioration" = col_post)) +
  labs(x = NULL, y = "Proportion", fill = NULL, title = "Évolution individuelle : amélioration vs stabilité vs diminution") +
  theme_article(base_size = 12) +
  theme(legend.position = "none")
```

Interprétation : ce graphique répond à une question simple : “combien de participantes s’améliorent, restent stables ou diminuent ?” (sans tenir compte de l’ampleur).

#### Courbe ECDF des gains (Q2 − Q1)

La courbe ECDF montre, pour chaque valeur *x*, la proportion de participantes ayant un gain **<= x**. On peut lire directement la proportion avec un gain >= 3 en regardant ce qu’il reste au-dessus de x = 3.

```{r}
ec <- ecdf(data_matched$score_diff)
prop_ge_3 <- mean(data_matched$score_diff >= 3)

ggplot(data_matched, aes(x = score_diff)) +
  stat_ecdf(geom = "step", linewidth = 1, color = "grey20") +
  geom_vline(xintercept = 3, linetype = "dotted", color = "grey35") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(
    x = "Gain (Q2 − Q1)",
    y = "Proportion avec gain <= x",
    title = "ECDF des gains (Q2 − Q1)",
    subtitle = paste0("Proportion avec gain >= 3 : ", scales::percent(prop_ge_3, accuracy = 0.1))
  ) +
  theme_article(base_size = 12)
```

#### Bootstrap (1000 repiquages) du gain moyen

Objectif : estimer l'incertitude du **gain moyen** sans s'appuyer sur l'hypothèse de normalité (repiquage des participantes appariées).

```{r}
set.seed(123)

B <- 1000
n <- nrow(data_matched)

boot_idx <- replicate(B, sample.int(n, size = n, replace = TRUE))

boot_mean_pre <- apply(boot_idx, 2, \(idx) mean(data_matched$score_pre[idx]))
boot_mean_post <- apply(boot_idx, 2, \(idx) mean(data_matched$score_post[idx]))
boot_mean_diff <- apply(boot_idx, 2, \(idx) mean(data_matched$score_diff[idx]))

boot <- tibble(
  rep = seq_len(B),
  mean_pre = boot_mean_pre,
  mean_post = boot_mean_post,
  mean_diff = boot_mean_diff
)
mean_diff_obs <- mean(data_matched$score_diff)
ci_diff <- quantile(boot$mean_diff, probs = c(0.025, 0.975))

knitr::kable(tibble(
  `n` = n,
  `B (réplications)` = B,
  `Gain moyen observé` = round(mean_diff_obs, 2),
  `IC95% (2,5%)` = round(unname(ci_diff[1]), 2),
  `IC95% (97,5%)` = round(unname(ci_diff[2]), 2)
), align = "l")
```

Interprétation (bootstrap, 1000 réplications) : l’IC95% bootstrap du gain moyen est **[`r round(ci_diff[1], 2)`, `r round(ci_diff[2], 2)`]**. Cet intervalle est compatible avec un gain moyen > 0 et montre que le gain moyen est plutôt autour de 2–3 points.

#### Densités (avant bootstrap) et densités des moyennes (bootstrap)

Le premier graphique représente la distribution des **scores individuels observés**. Le second représente la distribution bootstrap des **moyennes** (après 1000 repiquages). La ligne verticale pointillée correspond à la moyenne observée.

```{r}
obs_means <- tibble(
  time = factor(c("Avant (Q1)", "Après (Q2)"), levels = c("Avant (Q1)", "Après (Q2)")),
  mean_score = c(mean(data_matched$score_pre), mean(data_matched$score_post))
)

ggplot(data_matched_long, aes(x = score, fill = time, color = time)) +
  geom_density(alpha = 0.25, linewidth = 0.8) +
  geom_vline(
    data = obs_means,
    aes(xintercept = mean_score, color = time),
    linetype = "dashed",
    linewidth = 1
  ) +
  scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_color_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = "Score individuel observé", y = "Densité", fill = NULL, color = NULL) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "top")
```

Interprétation (densités observées) : la densité “Après (Q2)” est globalement décalée vers la droite par rapport à “Avant (Q1)”, ce qui est cohérent avec un gain global. Le recouvrement entre courbes reflète l’hétérogénéité interindividuelle.

```{r}
boot_means_long <- boot %>%
  select(mean_pre, mean_post) %>%
  pivot_longer(cols = c(mean_pre, mean_post), names_to = "time", values_to = "mean_score") %>%
  mutate(
    time = recode(time, mean_pre = "Avant (Q1)", mean_post = "Après (Q2)"),
    time = factor(time, levels = c("Avant (Q1)", "Après (Q2)"))
  )

ggplot(boot_means_long, aes(x = mean_score, fill = time, color = time)) +
  geom_density(alpha = 0.25, linewidth = 0.8) +
  geom_vline(
    data = obs_means,
    aes(xintercept = mean_score, color = time),
    linetype = "dashed",
    linewidth = 1
  ) +
  scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_color_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  labs(x = "Moyenne bootstrap du score", y = "Densité", fill = NULL, color = NULL) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "top")
```

Interprétation (densités bootstrap des moyennes) : ces courbes décrivent l’incertitude sur la **moyenne** de Q1 et Q2. Si la moyenne bootstrap de Q2 est nettement au-dessus de celle de Q1, l’amélioration moyenne est robuste aux hypothèses de normalité.

#### Résumé des gains

```{r}
gain_summary_tbl <- data_matched %>%
  summarise(
    n = n(),
    mean_pre = round(mean(score_pre), 2),
    mean_post = round(mean(score_post), 2),
    mean_diff = round(mean(score_diff), 2),
    sd_diff = round(sd(score_diff), 2),
    median_diff = round(median(score_diff), 2),
    iqr_diff = round(IQR(score_diff), 2),
    prop_improved = scales::percent(mean(score_diff >= 0), accuracy = 0.1)
  )

knitr::kable(gain_summary_tbl, col.names = c("n", "Moy. Q1", "Moy. Q2", "Gain moy.", "SD gain", "Médiane gain", "IQR gain", "% améliorées"), align = "l")
```

#### Pertinence clinique : proportion avec gain >= 3 points

```{r}
#| output: false
n_tot <- nrow(data_matched)
n_clin <- sum(data_matched$score_diff >= delta_clin)
bt_clin_prop <- binom.test(n_clin, n_tot)
```

Interprétation (proportion avec gain >= 3) : `r n_clin`/`r n_tot` participantes (`r round(100*n_clin/n_tot, 1)`%) atteignent au moins 3 points. IC95% de cette proportion : [`r round(bt_clin_prop$conf.int[1], 3)`, `r round(bt_clin_prop$conf.int[2], 3)`].

Note : la sortie `binom.test` affiche aussi une p-value (test contre une proportion de 0,5 par défaut). Ici, cette p-value n’est **pas** l’objectif principal ; l’intérêt est surtout l’**estimation** de la proportion et son **IC95%**.

#### Probabilité d'un gain >= 3 points selon le score initial

::: {.callout-note title="Objectif de cette analyse"}
Cette section vise à quantifier l'**effet plafond**. On s'attend à ce qu'il soit plus difficile d'obtenir un gros gain (>= 3 points) si le score de départ est déjà élevé. Le modèle de régression logistique estime la **probabilité** que cela arrive, en fonction du score de départ. Le graphique qui suit est la visualisation de cette probabilité.
:::

Objectif : estimer, à partir des données, la **probabilité** d’obtenir un gain d’au moins 3 points (Q2 − Q1 >= 3) en fonction du score initial, puis donner une estimation **pour un score initial égal à la moyenne observée au Q1 dans l’échantillon apparié** (`r fmt_num(mean(data_matched$score_pre, na.rm = TRUE), 2)`/20).

Explication simple : on définit “répondeur” = 1 si la participante gagne au moins 3 points, sinon 0. On ajuste ensuite une régression logistique pour relier la probabilité d’être répondeur au **score initial**. Le modèle sert à résumer la tendance globale (une courbe) et à lire la probabilité pour un score initial donné.

```{r}
target_pre <- mean(data_matched$score_pre, na.rm = TRUE)

data_resp <- data_matched %>%
  mutate(responder = score_diff >= delta_clin) %>%
  filter(!is.na(score_pre))

# Modèle simple (visualisation) : score initial seul
mod_resp_simple <- glm(responder ~ score_pre, data = data_resp, family = binomial())

pred_target <- predict(
  mod_resp_simple,
  newdata = tibble(score_pre = target_pre),
  type = "link",
  se.fit = TRUE
)

p_hat <- plogis(pred_target$fit[[1]])
p_low <- plogis(pred_target$fit[[1]] - 1.96 * pred_target$se.fit[[1]])
p_high <- plogis(pred_target$fit[[1]] + 1.96 * pred_target$se.fit[[1]])

resp_tbl <- tibble(
  `Score initial (Q1, /20)` = round(target_pre, 2),
  `Probabilité estimée (gain >= 3)` = p_hat,
  `IC95% bas` = p_low,
  `IC95% haut` = p_high
) %>%
  mutate(across(where(is.numeric), ~ round(.x, 4))) %>%
  mutate(across(matches("^(Probabilité|IC95%)"), ~ scales::percent(.x, accuracy = 0.1)))

knitr::kable(resp_tbl, align = "l")
```

Analyse complémentaire (exploratoire) : on ajuste aussi un modèle “complet” (score initial + âge + langue) et un modèle “âge seul” (score initial + âge) pour vérifier si l’âge et/ou la langue apportent une information supplémentaire sur la probabilité d’un gain >= 3 points, à score initial comparable.

```{r}
data_resp_full <- data_matched %>%
  mutate(responder = score_diff >= delta_clin) %>%
  filter(!is.na(score_pre), !is.na(age_years), langue_q1 %in% c("Français", "Créole"))

# Modèle ajusté (exploratoire) : score initial + âge (approché en années) + langue
mod_resp <- glm(responder ~ score_pre + age_years + langue_q1, data = data_resp_full, family = binomial())

or_table <- function(mod) {
  sm <- summary(mod)$coefficients
  out <- tibble(
    term = rownames(sm),
    estimate = sm[, "Estimate"],
    se = sm[, "Std. Error"],
    p_value = sm[, "Pr(>|z|)"]
  ) %>%
    mutate(
      OR = exp(estimate),
      OR_low = exp(estimate - 1.96 * se),
      OR_high = exp(estimate + 1.96 * se),
      p = fmt_p(p_value)
    ) %>%
    select(term, OR, OR_low, OR_high, p)

  out
}

or_full <- or_table(mod_resp) %>%
  mutate(
    term = recode(
      term,
      "score_pre" = "Score initial (Q1) (par +1 point)",
      "age_years" = "Âge (par +1 an)",
      "langue_q1Créole" = "Langue: Créole (vs Français)"
    )
  ) %>%
  filter(term != "(Intercept)")

knitr::kable(or_full, col.names = c("Variable", "OR", "IC95% bas", "IC95% haut", "p"), align = "l")

# Valeurs utiles pour une interprétation simple (score initial)
or_score_pre <- or_full %>%
  filter(term == "Score initial (Q1) (par +1 point)") %>%
  pull(OR) %>%
  dplyr::first()
or_score_pre_drop_pct <- (1 - or_score_pre) * 100
```

Interprétation (modèle complet) : dans ces données, on n’observe **pas d’effet clair de l’âge** ni de la **langue du questionnaire** (IC95% des OR recouvrant 1 et p > 0,05). En revanche, le **score initial** est fortement associé à la probabilité d’un gain >= 3 : plus le score de départ est élevé, plus la probabilité d’un “gros gain” diminue (effet plafond). Concrètement, l’OR associé au score initial est d’environ **`r round(or_score_pre, 2)`** par +1 point : cela correspond à une baisse d’environ **`r round(or_score_pre_drop_pct, 0)`%** des “chances” (odds) d’atteindre un gain >= 3 pour chaque point supplémentaire au score initial.

```{r}
# Modèle "âge seul" (sans langue) : score initial + âge
mod_resp_age <- glm(responder ~ score_pre + age_years, data = data_resp_full, family = binomial())

or_age <- or_table(mod_resp_age) %>%
  mutate(
    term = recode(
      term,
      "score_pre" = "Score initial (Q1) (par +1 point)",
      "age_years" = "Âge (par +1 an)"
    )
  ) %>%
  filter(term != "(Intercept)")

knitr::kable(or_age, col.names = c("Variable", "OR", "IC95% bas", "IC95% haut", "p"), align = "l")
```

Interprétation (modèle âge seul) : ce modèle permet d’évaluer l’association entre l’âge et la probabilité d’un gain >= 3, sans tenir compte de la langue. Si l’effet de l’âge est proche de 1 et non significatif, cela suggère une faible influence de l’âge dans ces données.

```{r}
grid <- tibble(score_pre = seq(0, 20, by = 0.1))
pred_grid <- predict(mod_resp_simple, newdata = grid, type = "link", se.fit = TRUE)
grid <- grid %>%
  mutate(
    p = plogis(pred_grid$fit),
    p_low = plogis(pred_grid$fit - 1.96 * pred_grid$se.fit),
    p_high = plogis(pred_grid$fit + 1.96 * pred_grid$se.fit)
  )

ggplot(grid, aes(x = score_pre, y = p)) +
  geom_ribbon(aes(ymin = p_low, ymax = p_high), alpha = 0.16, fill = col_post) +
  geom_line(linewidth = 1.1, color = col_post) +
  geom_vline(xintercept = target_pre, linetype = "dotted", color = "grey35") +
  geom_point(data = tibble(score_pre = target_pre, p = p_hat), aes(x = score_pre, y = p), size = 2.4, color = col_post) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  scale_x_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(
    x = "Score initial (Q1, /20)",
    y = "Probabilité estimée d’un gain >= 3 points",
    title = "Probabilité de gain >= 3 points selon le score initial",
    subtitle = "Courbe issue d'un modèle logistique (score initial seul) avec IC95%"
  ) +
  theme_article(base_size = 12)
```

Interprétation : globalement, la courbe est décroissante : quand le score initial augmente, la probabilité d’obtenir un gain >= 3 diminue (effet plafond). Pour un score initial égal à la **moyenne du Q1 dans l’échantillon apparié** (**`r fmt_num(target_pre, 2)`/20**), la probabilité estimée est d’environ **`r scales::percent(p_hat, accuracy = 0.1)`** (IC95% : **[`r scales::percent(p_low, accuracy = 0.1)`, `r scales::percent(p_high, accuracy = 0.1)`]**).

#### Test de signe (proportion de paires améliorées)

Le test de signe compare le nombre de paires où le score augmente vs diminue (les égalités sont ignorées).

```{r}
#| output: false
n_pos <- sum(data_matched$score_diff > 0, na.rm = TRUE)
n_neg <- sum(data_matched$score_diff < 0, na.rm = TRUE)
n_ties <- sum(data_matched$score_diff == 0, na.rm = TRUE)

sign_test <- NULL
if ((n_pos + n_neg) > 0) {
  sign_test <- binom.test(n_pos, n_pos + n_neg, p = 0.5, alternative = "greater")
}
```

Interprétation (test de signe) : `r if (is.null(sign_test)) "non interprétable (toutes les différences sont nulles)." else paste0("test ", sig_txt(sign_test$p.value, alpha), " (p = ", fmt_p(sign_test$p.value), "). ", "Cela indique que les améliorations (gain > 0) sont ", ifelse(sign_test$p.value < alpha, "plus fréquentes", "pas plus fréquentes de façon démontrée"), " que les diminutions (gain < 0), indépendamment de l’amplitude des variations.")`

### Exploration : gain global selon l'âge

```{r}
data_matched %>%
  select(age_group, score_pre, score_post, score_diff) %>%
  tbl_summary(
    by = age_group,
    statistic = list(all_continuous() ~ "{mean} ± {sd}"),
    digits = all_continuous() ~ 2,
    missing = "no"
  ) %>%
  add_n() %>%
  bold_labels()
```

Interprétation (stratifié par âge) : ces moyennes (± SD) permettent de comparer le niveau initial, le niveau après intervention et le gain moyen selon la tranche d’âge, avant de formaliser la comparaison par tests.

#### Répondeurs (gain >= 3) selon l'âge (exploratoire)

```{r}
resp_age <- data_matched %>%
  filter(age_group != "Inconnu") %>%
  group_by(age_group) %>%
  summarise(
    n = n(),
    x = sum(score_diff >= 3),
    p = x / n,
    ci = list(wilson_ci(x, n)),
    .groups = "drop"
  ) %>%
  mutate(
    ci_low = vapply(ci, \(v) v[1], numeric(1)),
    ci_high = vapply(ci, \(v) v[2], numeric(1))
  )

knitr::kable(
  resp_age %>%
  transmute(
    `Âge` = age_group,
    `n` = n,
    `Répondeurs (gain >= 3)` = paste0(x, "/", n, " (", scales::percent(p, accuracy = 0.1), ")"),
    `IC95%` = paste0("[", scales::percent(ci_low, accuracy = 0.1), " ; ", scales::percent(ci_high, accuracy = 0.1), "]")
  ),
  align = "l"
)
```

```{r}
ggplot(resp_age, aes(x = age_group, y = p)) +
  geom_col(fill = col_post, alpha = 0.85, width = 0.75) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.18, color = "grey20") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  labs(
    x = NULL,
    y = "Proportion de répondeurs (gain >= 3)",
    title = "Répondeurs (gain >= 3) selon l'âge (exploratoire)"
  ) +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Interprétation : ces proportions (avec IC95%) permettent de voir si un “gros gain” (>= 3 points) semble plus fréquent dans certaines tranches d’âge. Résultat exploratoire.

```{r}
ggplot(data_matched, aes(x = age_group, y = score_diff)) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.6) +
  geom_boxplot(outlier.alpha = 0.2, fill = col_post, alpha = 0.35) +
  geom_jitter(width = 0.15, alpha = 0.25, size = 1, color = "grey25") +
  labs(x = NULL, y = "Gain (Q2 - Q1) sur le score global") +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Interprétation (gain vs âge) : ce boxplot compare la distribution des gains par tranche d’âge. Un écart de médiane ou une dispersion très différente suggère des sous-groupes répondant mieux ou moins bien à l’intervention.

### Score initial (Q1) selon l'âge

```{r}
ggplot(data_matched, aes(x = age_group, y = score_pre)) +
  geom_boxplot(outlier.alpha = 0.2, fill = col_pre, alpha = 0.35) +
  geom_jitter(width = 0.15, alpha = 0.25, size = 1, color = "grey25") +
  scale_y_continuous(limits = c(0, 20), breaks = seq(0, 20, 2)) +
  labs(x = NULL, y = "Score initial (Q1)") +
  theme_article(base_size = 12) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Interprétation (score initial vs âge) : ce boxplot aide à repérer des niveaux de connaissance initiaux différents selon l’âge, ce qui peut influencer le gain possible (“marge de progression”).

```{r}
#| output: false
kw_age_pre <- kruskal.test(score_pre ~ age_group, data = data_matched %>% filter(age_group != "Inconnu"))
```

Interprétation (Kruskal–Wallis, score initial vs âge) : test `r sig_txt(kw_age_pre$p.value, alpha)` (p = `r fmt_p(kw_age_pre$p.value)`). Un résultat significatif suggère des distributions de score initial différentes selon la tranche d’âge.

```{r}
#| output: false
kw_age <- kruskal.test(score_diff ~ age_group, data = data_matched %>% filter(age_group != "Inconnu"))
```

Interprétation (Kruskal–Wallis, gain vs âge) : test `r sig_txt(kw_age$p.value, alpha)` (p = `r fmt_p(kw_age$p.value)`). Un résultat significatif suggère une réponse à l’intervention hétérogène selon l’âge.

```{r}
#| output: false
lm_age <- lm(score_diff ~ age_group + score_pre, data = data_matched %>% filter(age_group != "Inconnu"))
anova_age <- anova(lm_age)
```

Interprétation (modèle linéaire) : après ajustement sur le score initial, l’association globale avec l’âge est `r sig_txt(anova_age[["Pr(>F)"]][1], alpha)` (p = `r fmt_p(anova_age[["Pr(>F)"]][1])`). Le score initial est `r sig_txt(anova_age[["Pr(>F)"]][2], alpha)` (p = `r fmt_p(anova_age[["Pr(>F)"]][2])`), ce qui peut traduire un effet plafond (gain plus faible quand le score initial est déjà élevé).

### Scores initiaux par question (Q1)

```{r}
plot_q1_question <- function(df_q) {
  q_label <- unique(df_q$label)
  max_pts <- unique(df_q$max_points)
  if (length(q_label) != 1 || length(max_pts) != 1) stop("Question data malformed")

  score_levels <- 0:max_pts
  dist_q1 <- df_q %>%
    mutate(score_pts = as.integer(score_pre)) %>%
    count(score_pts, name = "x") %>%
    tidyr::complete(score_pts = score_levels, fill = list(x = 0)) %>%
    mutate(n = sum(x), p = x / n, score_pts_f = factor(score_pts, levels = score_levels)) %>%
    rowwise() %>%
    mutate(
      ci = list(wilson_ci(x, n)),
      ci_low = ci[[1]][1],
      ci_high = ci[[1]][2]
    ) %>%
    ungroup() %>%
    select(-ci)

  ggplot(dist_q1, aes(x = score_pts_f, y = p)) +
    geom_col(fill = col_pre, alpha = 0.9, width = 0.75) +
    geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.15, linewidth = 0.5, color = "grey35") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
    labs(
      title = q_label,
      x = sprintf("Score initial (points, max = %d)", max_pts),
      y = "Proportion de participantes"
    ) +
    theme_article(base_size = 11)
}
```

```{r, results="asis"}
for (q in unique(by_question$label)) {
  df_q <- by_question %>% filter(label == q)
  cat("\n\n**", q, "**\n\n", sep = "")
  print(plot_q1_question(df_q))
}
```

Lorsque les réponses initiales sont bonnes (quasi 100% au score maximal), il existe un probable "effet plafond" de la question, limitant la marge de progression possible.

Vue d'ensemble des 8 questions sur un seul graphique facetté :

```{r}
#| label: plot_q1_facetted
#| fig-width: 12
#| fig-height: 10

facet_data_q1 <- by_question %>%
  mutate(
    score_pct = (score_pre / max_points) * 100,
    label_wrap = stringr::str_wrap(label, width = 35)
  )

facet_summary_q1 <- facet_data_q1 %>%
  group_by(label_wrap, max_points) %>%
  summarise(
    mean_pct = mean(score_pct),
    median_pct = median(score_pct),
    .groups = "drop"
  )

ggplot(facet_data_q1, aes(x = score_pct)) +
  geom_histogram(binwidth = 10, boundary = 0, fill = col_pre, alpha = 0.8, color = "white") +
  geom_vline(data = facet_summary_q1, aes(xintercept = mean_pct),
             linetype = "dashed", color = "grey25", linewidth = 0.6) +
  facet_wrap(~ label_wrap, ncol = 2, scales = "free_y") +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1), limits = c(-5, 105)) +
  labs(
    x = "Score initial (% du barème)",
    y = "Effectif",
    title = "Distribution des scores initiaux (Q1) par question",
    subtitle = "Ligne pointillée = moyenne. Les questions proches de 100% montrent un effet plafond."
  ) +
  theme_article(base_size = 11)
```

Représentons tous les scores sur un même graphique pour mieux visualiser les différences entre questions, avec un barème normalisé (0–100%).

```{r}
#| label: plot_q1_all_questions
#| fig-width: 12
#| fig-height: 6
#| echo: false
#| message: false
#| warning: false
q1_all <- by_question %>%
  group_by(label, max_points) %>%
  summarise(
    n = n(),
    mean_pre = mean(score_pre),
    prop_full_pre = mean(full_pre),
    .groups = "drop"
  ) %>%
  mutate(
    mean_pre_pct = (mean_pre / max_points) * 100,
    label_wrap = stringr::str_wrap(label, width = 40)
  )
ggplot(q1_all, aes(x = reorder(label_wrap, -mean_pre_pct), y = mean_pre_pct)) +
  geom_col(fill = col_pre, alpha = 0.9, width = 0.7) +
  geom_text(aes(label = paste0(round(mean_pre_pct, 1), "%")), vjust = -0.5, size = 3) +
  scale_y_continuous(
    labels = scales::label_percent(accuracy = 1, scale = 1),
    limits = c(0, 100)
  ) +
  labs(
    x = NULL,
    y = "Score initial moyen (% du barème)"
  ) +
  theme_article(base_size = 11) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

## Analyse par question

Cette section explore l’évolution **par question** (scores en points et en % du barème) à partir des scores par question déjà calculés plus haut.

Important : ces analyses “par question” sont **exploratoires**. Il n’y a pas de correction pour tests multiples (demande explicite), donc on interprète surtout (i) la **taille** des gains (en points et en % du barème) et (ii) la cohérence avec l’effet plafond, plutôt qu’une liste stricte de p-values < 0,05.

```{r}
#| output: false
# Contrôles de cohérence du scoring par question
by_question %>%
  summarise(
    n = n(),
    n_pre_out_of_range = sum(score_pre < 0 | score_pre > max_points),
    n_post_out_of_range = sum(score_post < 0 | score_post > max_points)
  )
```

### Résultats par question

```{r}
q_summary_tbl <- by_question %>%
  group_by(label, max_points) %>%
  summarise(
    n = n(),
    mean_pre = mean(score_pre),
    mean_post = mean(score_post),
    mean_diff = mean(score_diff),
    prop_full_pre = mean(full_pre),
    prop_full_post = mean(full_post),
    .groups = "drop"
  ) %>%
  mutate(
    mean_pre = round(mean_pre, 2),
    mean_post = round(mean_post, 2),
    mean_diff = round(mean_diff, 2),
    prop_full_pre = scales::percent(prop_full_pre, accuracy = 0.1),
    prop_full_post = scales::percent(prop_full_post, accuracy = 0.1)
  ) %>%
  select(Question = label, `Max` = max_points, n, `Moy. Q1` = mean_pre, `Moy. Q2` = mean_post, `Gain moy.` = mean_diff, `% max Q1` = prop_full_pre, `% max Q2` = prop_full_post)

knitr::kable(q_summary_tbl, align = "l")
```

Interprétation (résumé par question) : la comparaison des moyennes (en points) et des proportions au score maximal (“full score”) permet d’identifier des questions déjà très bien réussies avant (effet plafond) versus celles ayant une marge de progression importante.

### Exploration par âge : gain par question (% du barème)

```{r}
q_age <- by_question %>%
  mutate(diff_pct = (score_diff / max_points) * 100) %>%
  filter(age_group != "Inconnu") %>%
  group_by(label, age_group) %>%
  summarise(
    n = n(),
    mean_diff_pct = mean(diff_pct),
    se = sd(diff_pct) / sqrt(n()),
    ci_low = mean_diff_pct - 1.96 * se,
    ci_high = mean_diff_pct + 1.96 * se,
    .groups = "drop"
  )

ggplot(q_age, aes(x = age_group, y = mean_diff_pct)) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.6) +
  geom_point(color = col_post, size = 2) +
  geom_errorbar(aes(ymin = ci_low, ymax = ci_high), width = 0.15, linewidth = 0.5, color = "grey35") +
  facet_wrap(~ label, ncol = 2) +
  labs(x = NULL, y = "Gain moyen (% du barème, Q2 - Q1)") +
  theme_article(base_size = 11) +
  theme(axis.text.x = element_text(angle = 35, hjust = 1))
```

Interprétation (âge × question) : ces points (± IC95%) comparent les gains moyens par tranche d’âge pour chaque question, afin de repérer des items où certains groupes progressent davantage.

```{r}
q_age_tests <- by_question %>%
  mutate(diff_pct = (score_diff / max_points) * 100) %>%
  filter(age_group != "Inconnu") %>%
  group_by(label) %>%
  summarise(
    n = n(),
    p_kw = kruskal.test(diff_pct ~ age_group)$p.value,
    .groups = "drop"
  ) %>%
  mutate(
    p_kw_fmt = fmt_p(p_kw)
  ) %>%
  arrange(p_kw)

knitr::kable(q_age_tests %>% select(Question = label, n, `p (Kruskal-Wallis)` = p_kw_fmt), align = "l")
```

Interprétation (âge × questions) : `r sum(q_age_tests$p_kw < alpha, na.rm = TRUE)` question(s) montrent une hétérogénéité des gains selon l’âge (p < `r alpha`). Résultat exploratoire, sans correction pour multiplicité.

### Synthèse des gains par question

Pour avoir une vue d'ensemble, le graphique suivant représente le gain moyen pour chaque question, exprimé en **pourcentage du barème maximum de la question**. Les questions sont triées de celle qui a le plus progressé à celle qui a le moins progressé.

```{r}
#| label: plot_gain_by_question_summary
#| fig-width: 8
#| fig-height: 6

q_gains_summary <- by_question %>%
  group_by(label, max_points) %>%
  summarise(
    mean_pre = mean(score_pre),
    mean_post = mean(score_post),
    gain_abs = mean_post - mean_pre,
    gain_pct = (mean_post - mean_pre) / max_points * 100,
    .groups = "drop"
  ) %>%
  mutate(label_wrap = stringr::str_wrap(label, width = 40))

ggplot(q_gains_summary, aes(x = reorder(label_wrap, gain_pct), y = gain_pct)) +
  geom_segment(aes(xend = reorder(label_wrap, gain_pct), yend = 0), color = "grey") +
  geom_point(color = col_post, size = 4, alpha = 0.8) +
  geom_text(aes(label = paste0("+", round(gain_pct, 1), "%")), hjust = -0.4, size = 3, color = "grey20") +
  coord_flip() +
  scale_y_continuous(limits = c(min(q_gains_summary$gain_pct) - 5, max(q_gains_summary$gain_pct) + 10)) +
  labs(
    x = NULL,
    y = "Gain moyen (% du barème de la question)",
    title = "Classement des questions selon le gain de score moyen",
    subtitle = "Permet d'identifier les connaissances les plus améliorées par l'intervention"
  ) +
  theme_article(base_size = 12) +
  theme(
    panel.grid.major.vertical = element_blank(),
    panel.grid.major.horizontal = element_line(linetype = "dotted", color = "grey80")
  )
```

Interprétation : Ce graphique synthétise l'impact de l'intervention sur chaque connaissance spécifique. On voit immédiatement que les questions sur `r q_gains_summary %>% arrange(desc(gain_pct)) %>% distinct(label) %>% slice_head(n = 2) %>% pull(label) %>% paste(collapse = ' et ')` ont montré la plus forte progression, tandis que d'autres, probablement déjà bien maîtrisées au départ, ont peu évolué.

### Tests par question (appariés)

Pour chaque item, on teste si le score augmente après intervention (unilatéral : après > avant). Pour les questions à score binaire, cela correspond à une amélioration du taux de “bonne réponse”.

```{r}
test_by_question <- by_question %>%
  group_by(label) %>%
  summarise(
    n = n(),
    p_t = t.test(score_post, score_pre, paired = TRUE, alternative = "greater")$p.value,
    p_mcnemar_full = {
      tab <- table(full_pre, full_post)
      if (all(dim(tab) == c(2, 2))) mcnemar.test(tab, correct = TRUE)$p.value else NA_real_
    },
    .groups = "drop"
  ) %>%
  mutate(
    p_t_fmt = fmt_p(p_t),
    p_mcnemar_full_fmt = fmt_p(p_mcnemar_full)
  )

knitr::kable(test_by_question %>%
  select(
    Question = label, n,
    `p (t-test)` = p_t_fmt,
    `p (McNemar)` = p_mcnemar_full_fmt
  ), align = "l")
```

Interprétation (tests par question) : `r sum(test_by_question$p_t < alpha, na.rm = TRUE)` question(s) sont significativement améliorées (t-test apparié), résultats exploratoires sans correction pour multiplicité.

### Graphique : score moyen par question (avant vs après)

```{r}
#| label: plot_q_means_dumbbell
#| fig-width: 8
#| fig-height: 6

# Calcul des moyennes par question (qui avait été oublié)
q_means <- by_question %>%
  pivot_longer(cols = c(score_pre, score_post), names_to = "time", values_to = "score") %>%
  mutate(time = recode(time, score_pre = "Avant (Q1)", score_post = "Après (Q2)")) %>%
  group_by(label, max_points, time) %>%
  summarise(
    mean = mean(score / max_points) * 100,
    se = sd(score / max_points * 100) / sqrt(n()),
    .groups = "drop"
  )

# Préparation des données pour le dumbbell plot
q_dumbbell_data <- q_means %>%
  pivot_wider(names_from = time, values_from = c(mean, se)) %>%
  mutate(label_wrap = stringr::str_wrap(label, 45))

ggplot(
  q_dumbbell_data,
  aes(y = reorder(label_wrap, `mean_Après (Q2)`), x = `mean_Avant (Q1)`, xend = `mean_Après (Q2)`)
) +
  # Le trait du dumbbell
  geom_segment(
    aes(yend = reorder(label_wrap, `mean_Après (Q2)`)),
    color = "grey",
    linewidth = 1.5,
    alpha = 0.7
  ) +
  # Point "Avant"
  geom_point(aes(color = "Avant (Q1)"), size = 4) +
  # Point "Après"
  geom_point(aes(x = `mean_Après (Q2)`, color = "Après (Q2)"), size = 4) +
  # Thème et couleurs
  scale_color_manual(
    name = NULL,
    values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post),
    guide = guide_legend(override.aes = list(size = 4))
  ) +
  scale_x_continuous(limits = c(0, 100), labels = scales::percent_format(scale = 1)) +
  labs(
    x = "Score moyen (% du barème)",
    y = NULL,
    title = "Évolution du score moyen pour chaque question",
    subtitle = "Le trait représente le gain entre le score avant (bleu) et après (vert)"
  ) +
  theme_article() +
  theme(legend.position = "bottom")

```

```{r}
q_improve <- by_question %>%
  group_by(label, max_points) %>%
  summarise(
    mean_pre = mean(score_pre),
    mean_post = mean(score_post),
    diff_pct = (mean_post - mean_pre) / max_points * 100,
    .groups = "drop"
  ) %>%
  arrange(desc(diff_pct))
```

```{r}
top3_questions <- q_improve %>%
  distinct(label, .keep_all = TRUE) %>%
  arrange(desc(diff_pct)) %>%
  slice_head(n = 3) %>%
  pull(label)
```

Interprétation (moyennes par question) : les barres représentent la moyenne exprimée en **% du barème** (avec IC95%). Les plus fortes progressions moyennes concernent notamment : `r paste0(top3_questions, collapse = "; ")`.

### Effet plafond par question : proportion au score maximal

Idée : si une question est déjà très souvent au score maximal au Q1, il reste peu de marge de progression au Q2 (effet plafond).

```{r}
item_map <- key %>%
  mutate(Item = paste0("Q", row_number())) %>%
  select(Item, label, max_points)

knitr::kable(item_map, col.names = c("Item", "Question", "Barème max"), align = "l")
```

```{r}
full_tbl <- by_question %>%
  mutate(Item = paste0("Q", match(id, key$id))) %>%
  group_by(Item, label, max_points) %>%
  summarise(
    n = n(),
    x_pre = sum(full_pre),
    x_post = sum(full_post),
    p_pre = x_pre / n,
    p_post = x_post / n,
    ci_pre = list(wilson_ci(x_pre, n)),
    ci_post = list(wilson_ci(x_post, n)),
    .groups = "drop"
  ) %>%
  mutate(
    ci_pre_low = vapply(ci_pre, \(v) v[1], numeric(1)),
    ci_pre_high = vapply(ci_pre, \(v) v[2], numeric(1)),
    ci_post_low = vapply(ci_post, \(v) v[1], numeric(1)),
    ci_post_high = vapply(ci_post, \(v) v[2], numeric(1))
  )

full_long <- full_tbl %>%
  select(Item, time_pre = p_pre, time_post = p_post, ci_pre_low, ci_pre_high, ci_post_low, ci_post_high) %>%
  pivot_longer(cols = c(time_pre, time_post), names_to = "time", values_to = "p") %>%
  mutate(
    time = recode(time, time_pre = "Avant (Q1)", time_post = "Après (Q2)"),
    ci_low = ifelse(time == "Avant (Q1)", ci_pre_low, ci_post_low),
    ci_high = ifelse(time == "Avant (Q1)", ci_pre_high, ci_post_high),
    time = factor(time, levels = c("Avant (Q1)", "Après (Q2)"))
  )

ggplot(full_long, aes(x = Item, y = p, fill = time)) +
  geom_col(position = position_dodge(width = 0.75), width = 0.7) +
  geom_errorbar(
    aes(ymin = ci_low, ymax = ci_high),
    position = position_dodge(width = 0.75),
    width = 0.18,
    color = "grey20"
  ) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, 1)) +
  scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  labs(
    x = "Item",
    y = "Proportion au score maximal",
    fill = NULL,
    title = "Effet plafond par item : % au score maximal (avec IC95%)"
  ) +
  theme_article(base_size = 12)
```

Interprétation : si l’item est déjà très souvent “au maximum” au Q1, la hausse possible au Q2 est mécaniquement limitée (effet plafond).

### Distribution des scores par question (1 graphique par question)

Abscisse = **score en points** (0 à barème max) ; ordonnée = **% de participantes** (avec IC95%).

```{r}
stars_from_p <- function(p) {
  if (is.na(p)) return("")
  if (p < 0.001) return("***")
  if (p < 0.01) return("**")
  if (p < 0.05) return("*")
  ""
}

plot_one_question <- function(df_q) {
  q_label <- unique(df_q$label)
  max_pts <- unique(df_q$max_points)
  if (length(q_label) != 1 || length(max_pts) != 1) stop("Question data malformed")

  score_levels <- 0:max_pts

  long <- df_q %>%
    select(score_pre, score_post) %>%
    pivot_longer(cols = c(score_pre, score_post), names_to = "time", values_to = "score_pts") %>%
    mutate(
      time = recode(time, score_pre = "Avant (Q1)", score_post = "Après (Q2)"),
      time = factor(time, levels = c("Avant (Q1)", "Après (Q2)")),
      score_pts = as.integer(score_pts),
      score_pts_f = factor(score_pts, levels = score_levels)
    )

  dist <- long %>%
    count(time, score_pts_f, name = "x") %>%
    tidyr::complete(time, score_pts_f, fill = list(x = 0)) %>%
    group_by(time) %>%
    mutate(n = sum(x), p = x / n) %>%
    rowwise() %>%
    mutate(
      ci = list(wilson_ci(x, n)),
      ci_low = ci[[1]][1],
      ci_high = ci[[1]][2]
    ) %>%
    ungroup() %>%
    select(-ci)

  # Stars: McNemar on indicator(score==k), p < 0.05 (exploratoire, non corrigé)
  sig <- tibble(score_pts = score_levels) %>%
    rowwise() %>%
    mutate(
      p = {
        pre <- df_q$score_pre == score_pts
        post <- df_q$score_post == score_pts
        tab <- table(pre, post)
        if (all(dim(tab) == c(2, 2))) mcnemar.test(tab, correct = TRUE)$p.value else NA_real_
      }
    ) %>%
    ungroup() %>%
    mutate(star = vapply(p, stars_from_p, character(1)))

  star_pos <- dist %>%
    group_by(score_pts_f) %>%
    summarise(y = max(ci_high, na.rm = TRUE) + 0.04, .groups = "drop") %>%
    mutate(score_pts = as.integer(as.character(score_pts_f))) %>%
    left_join(sig, by = "score_pts") %>%
    filter(!is.na(star) & star != "")

  p_both <- ggplot(dist, aes(x = score_pts_f, y = p, fill = time)) +
    geom_col(position = position_dodge(width = 0.8), width = 0.75) +
    geom_errorbar(
      aes(ymin = ci_low, ymax = ci_high),
      position = position_dodge(width = 0.8),
      width = 0.15,
      linewidth = 0.5,
      color = "grey35"
    ) +
    geom_text(
      data = star_pos,
      aes(x = score_pts_f, y = y, label = star),
      inherit.aes = FALSE,
      size = 4,
      color = "grey15"
    ) +
    scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
    scale_y_continuous(
      labels = scales::percent_format(accuracy = 1),
      limits = c(0, 1),
      expand = expansion(mult = c(0.02, 0.08))
    ) +
    labs(
      title = q_label,
      x = sprintf("Score (points, max = %d)", max_pts),
      y = "Proportion de participantes",
      fill = NULL
    ) +
    theme_article(base_size = 11)

  list(plot = p_both, dist = dist, sig = sig)
}
```

```{r, results="asis"}
questions <- unique(by_question$label)

for (q in questions) {
  df_q <- by_question %>% filter(label == q)
  plots <- plot_one_question(df_q)

  cat("\n\n**", q, "**\n\n", sep = "")
  print(plots$plot)

  max_pts <- unique(df_q$max_points)
  mean_pre <- mean(df_q$score_pre)
  mean_post <- mean(df_q$score_post)
  diff_pct <- (mean_post - mean_pre) / max_pts * 100
  prop_full_pre <- mean(df_q$score_pre >= max_pts)
  prop_full_post <- mean(df_q$score_post >= max_pts)

  p_t <- t.test(df_q$score_post, df_q$score_pre, paired = TRUE, alternative = "greater")$p.value

  n_star <- sum(plots$sig$star != "" & !is.na(plots$sig$star))

  cat(
    "\nInterprétation : moyenne ",
    sprintf("%.2f", mean_pre), "/", max_pts, " (Q1) vs ",
    sprintf("%.2f", mean_post), "/", max_pts, " (Q2), soit ",
    sprintf("%.1f", diff_pct), "% du barème en moyenne. ",
    "Proportion au score maximal : ",
    sprintf("%.1f", 100 * prop_full_pre), "% (Q1) vs ",
    sprintf("%.1f", 100 * prop_full_post), "% (Q2). ",
    "Tests appariés : t-test ", sig_txt(p_t, alpha), " (p = ", fmt_p(p_t), ")",
    ". Astérisques (McNemar, p < 0,05) : ", n_star, " niveau(x) de score avec différence de proportion.\n",
    sep = ""
  )
}
```

### Vue d'ensemble : distribution Q1 vs Q2 (facettes)

```{r}
#| label: plot_q_dist_facetted
#| fig-width: 14
#| fig-height: 12

facet_q_long <- by_question %>%
  mutate(
    score_pre_pct = (score_pre / max_points) * 100,
    score_post_pct = (score_post / max_points) * 100,
    label_wrap = stringr::str_wrap(label, width = 30)
  ) %>%
  select(label_wrap, score_pre_pct, score_post_pct) %>%
  pivot_longer(
    cols = c(score_pre_pct, score_post_pct),
    names_to = "time",
    values_to = "score_pct"
  ) %>%
  mutate(
    time = recode(time, score_pre_pct = "Avant (Q1)", score_post_pct = "Après (Q2)"),
    time = factor(time, levels = c("Avant (Q1)", "Après (Q2)"))
  )

ggplot(facet_q_long, aes(x = score_pct, fill = time)) +
  geom_density(alpha = 0.35, linewidth = 0.6) +
  facet_wrap(~ label_wrap, ncol = 2, scales = "free_y") +
  scale_fill_manual(values = c("Avant (Q1)" = col_pre, "Après (Q2)" = col_post)) +
  scale_x_continuous(labels = scales::label_percent(accuracy = 1, scale = 1), limits = c(-5, 105)) +
  labs(
    x = "Score (% du barème)",
    y = "Densité",
    fill = NULL,
    title = "Évolution des distributions de scores par question (Q1 vs Q2)",
    subtitle = "Chaque facette montre le décalage entre avant et après intervention"
  ) +
  theme_article(base_size = 11) +
  theme(legend.position = "top")
```

Interprétation : cette vue d'ensemble permet de comparer visuellement les 8 questions sur un seul graphique. Un décalage de la densité vers la droite (vert vs bleu) indique une progression après l'intervention.

### Forest plot récapitulatif (gain global + par question)

Ce graphique de type "forest plot" résume sur un seul graphique le gain moyen global et les gains par question (avec IC95%), permettant une comparaison immédiate.

```{r}
#| label: plot_forest
#| fig-width: 10
#| fig-height: 7

# Gain global
global_ci <- t.test(data_matched$score_diff, conf.level = 0.95)
forest_global <- tibble(
  label = "GAIN GLOBAL",
  mean_gain_pct = mean(data_matched$score_diff) / 20 * 100,
  ci_low_pct = global_ci$conf.int[1] / 20 * 100,
  ci_high_pct = global_ci$conf.int[2] / 20 * 100,
  type = "global"
)

# Gains par question
forest_q <- by_question %>%
  group_by(label, max_points) %>%
  summarise(
    mean_gain = mean(score_diff),
    ci = list(t.test(score_diff, conf.level = 0.95)$conf.int),
    .groups = "drop"
  ) %>%
  mutate(
    mean_gain_pct = mean_gain / max_points * 100,
    ci_low_pct = sapply(ci, `[`, 1) / max_points * 100,
    ci_high_pct = sapply(ci, `[`, 2) / max_points * 100,
    type = "question",
    label = stringr::str_wrap(label, width = 35)
  ) %>%
  select(label, mean_gain_pct, ci_low_pct, ci_high_pct, type) %>%
  arrange(desc(mean_gain_pct))

forest_data <- bind_rows(forest_q, forest_global) %>%
  mutate(label = factor(label, levels = rev(label)))

ggplot(forest_data, aes(x = mean_gain_pct, y = label, color = type)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey50") +
  geom_errorbarh(aes(xmin = ci_low_pct, xmax = ci_high_pct), height = 0.2, linewidth = 0.6) +
  geom_point(aes(size = type), shape = 18) +
  scale_color_manual(values = c("global" = "grey15", "question" = col_post), guide = "none") +
  scale_size_manual(values = c("global" = 5, "question" = 3.5), guide = "none") +
  labs(
    x = "Gain moyen (% du barème, avec IC95%)",
    y = NULL,
    title = "Forest plot : gain par question et gain global",
    subtitle = "Un gain positif indique une amélioration après l'intervention"
  ) +
  theme_article(base_size = 12) +
  theme(
    panel.grid.major.y = element_line(linetype = "dotted", color = "grey90"),
    axis.text.y = element_text(size = 10)
  )
```

Interprétation : ce forest plot récapitule l'ensemble des résultats. Le losange noir en bas représente le gain global, tandis que les points verts montrent les gains par question. Les questions dont l'IC95% ne croise pas zéro sont celles où l'amélioration est statistiquement significative (à titre exploratoire, sans correction pour multiplicité).

## Discussion

### Résultats principaux

::: {.callout-tip title="Les 3 conclusions clés"}
1. **L'intervention a fonctionné :** amélioration statistiquement significative des connaissances, avec un gain moyen de **`r round(mean(data_matched$score_diff), 2)` points** (IC95% : [`r round(tt_two_sided$conf.int[1], 2)` ; `r round(tt_two_sided$conf.int[2], 2)`], d de Cohen = `r round(cohens_d, 2)`, effet `r d_interp`). Le message principal est positif.

2. **L'effet est modéré par un effet plafond :** le score de départ était déjà élevé (`r fmt_num(mean(data_matched$score_pre, na.rm = TRUE), 2)`/20), limitant la marge de progression. Le gain relatif moyen (`r round(rel_gain_summary$mean_rel, 1)`% de la marge disponible) est plus informatif que le gain brut.

3. **L'effet est homogène :** aucune différence significative selon l'âge (Kruskal-Wallis : p = `r fmt_p(kw_age$p.value)`). L'intervention bénéficie à toutes les participantes de manière comparable.
:::

Sur `r nrow(data_matched)` participantes appariées, le score moyen passe de **`r round(mean(data_matched$score_pre), 2)`/20** à **`r round(mean(data_matched$score_post), 2)`/20**, soit un gain moyen de **`r round(mean(data_matched$score_diff), 2)` point(s)** (t-test apparié : p = `r fmt_p(tt$p.value)`). En pratique, **`r n_clin`/`r n_tot`** participantes (**`r round(100*n_clin/n_tot, 1)`%**) ont un gain >= 3 points. L'analyse par question (exploratoire) montre que les plus fortes progressions concernent : `r paste0(top3_questions, collapse = "; ")`.

### Limites méthodologiques

1. **Biais de sélection (attrition) :** les participantes appariées avaient un score initial plus élevé que les non appariées, ce qui suggère un biais de sélection par motivation/engagement. L'analyse avant/après reste valide sur les paires, mais la généralisation doit être prudente. L'estimation d'un gain "avant/après" doit reposer sur les participantes ayant les deux mesures ; la moyenne Q2 "totale" (`r fmt_num(mean(q2_scores$score_q2_total_reported, na.rm = TRUE), 2)`/20 sur `r n_q2_total` réponses) reste descriptive et ne peut servir à estimer un gain.

2. **Appariement indirect :** l'appariement repose sur l'âge et la ville, sans identifiant unique. Toute erreur d'appariement tend à "diluer" l'effet mesuré.

3. **Absence de groupe contrôle :** sans groupe comparable, on ne peut pas attribuer formellement l'amélioration à la seule intervention. C'est une limite classique des études avant-après.

4. **QCM = connaissances, pas comportements :** mieux répondre au QCM ne garantit pas un changement de comportement, même si c'est un premier indicateur.

### Recommandations pour une future étude

1. **Identifiant unique anonyme** pour relier Q1 et Q2 de façon certaine et limiter les pertes au suivi.
2. **Groupe contrôle randomisé** (information différée à un autre groupe) pour isoler l'effet de l'intervention.
3. **Questionnaire plus discriminant** : questions plus difficiles pour limiter l'effet plafond et mieux discriminer les niveaux de connaissance.
4. **Critères de jugement élargis** : mesurer les intentions de changement, l'auto-efficacité, et idéalement des indicateurs de comportement, avec un suivi à distance (3-6 mois).

### Version thèse (paragraphe)

Dans cette étude avant-après (n = `r nrow(data_matched)` paires), le score moyen au QCM augmente de **`r round(mean(data_matched$score_pre), 2)`/20** avant information à **`r round(mean(data_matched$score_post), 2)`/20** après information, soit un gain moyen de **`r round(mean(data_matched$score_diff), 2)` point(s)** (d de Cohen = `r round(cohens_d, 2)`, effet `r d_interp`). Les tests appariés concluent à une amélioration statistiquement significative (t-test unilatéral : p = `r fmt_p(tt$p.value)`). L'intervalle de confiance bilatéral du gain moyen est **[`r round(tt_two_sided$conf.int[1], 2)` ; `r round(tt_two_sided$conf.int[2], 2)`]**. Au niveau individuel, **`r n_clin`/`r n_tot`** participantes (**`r round(100*n_clin/n_tot, 1)`%**) atteignent un gain >= 3 points. Le gain relatif moyen (rapporté à la marge de progression théorique) est de **`r round(rel_gain_summary$mean_rel, 1)`%**, ce qui permet de nuancer l'effet plafond observé sur le gain brut. L'analyse exploratoire par régression logistique (ajustée sur l'âge et la langue) confirme que le facteur principal est le score initial (effet plafond), sans effet clair de l'âge ni de la langue. L'analyse par question indique que les plus fortes progressions concernent : `r paste0(top3_questions, collapse = "; ")`.

Plusieurs limites peuvent influencer l'interprétation : l'appariement repose sur des informations indirectes (âge, ville), l'absence de groupe contrôle empêche d'attribuer formellement l'évolution au seul message d'information, et un QCM mesure surtout des connaissances à court terme. Pour améliorer l'évaluation dans une étude future, il serait souhaitable d'utiliser un identifiant unique, d'ajouter un groupe contrôle, de renforcer la sensibilité du questionnaire et d'intégrer des critères plus proches de l'objectif clinique, avec un suivi à distance pour évaluer la persistance de l'effet.

## Annexes techniques (détails statistiques)

Cette section regroupe des compléments “techniques” utiles pour un lecteur souhaitant vérifier certains points méthodologiques, sans alourdir l’interprétation principale.

### Diagnostic visuel (gain global)

```{r}
ggplot(data_matched, aes(sample = score_diff)) +
  stat_qq(color = "grey35", alpha = 0.6) +
  stat_qq_line(color = "grey15") +
  labs(
    x = "Quantiles théoriques",
    y = "Quantiles observés",
    title = "QQ-plot du gain (Q2 − Q1)"
  ) +
  theme_article(base_size = 12)
```

Interprétation : ce QQ-plot donne une idée de l’éloignement à la normalité. L’analyse principale ne repose pas uniquement sur la normalité car le bootstrap du gain moyen est également rapporté.
